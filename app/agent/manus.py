from typing import Any, Dict, List, Optional

from pydantic import Field, model_validator, PrivateAttr

from app.agent.browser import BrowserContextHelper
from app.agent.toolcall import ToolCallAgent
from app.config import config
from app.logger import logger
from app.prompt.manus import NEXT_STEP_PROMPT, SYSTEM_PROMPT, GREETING_TEMPLATE
from app.tool import BrowserUseTool, CVAnalyzerAgentTool, CVEditorAgentTool, CVOptimizerAgentTool, CVReaderAgentTool, GetResumeStructure, Terminate, ToolCollection
from app.tool.ask_human import AskHuman
from app.tool.mcp import MCPClients, MCPClientTool
from app.tool.python_execute import PythonExecute
from app.tool.str_replace_editor import StrReplaceEditor
from app.memory.conversation_manager import ConversationManager, Intent, ConversationState
from app.memory.langchain_memory import LangChainMemoryAdapter
from app.schema import Message, Role


class Manus(ToolCallAgent):
    """A versatile general-purpose agent with support for both local and MCP tools.

    é›†æˆ LangChain ConversationManager æä¾›æ™ºèƒ½å¯¹è¯ç®¡ç†ï¼š
    - è‡ªåŠ¨æ„å›¾è¯†åˆ«
    - ä¸Šä¸‹æ–‡è¿½è¸ª
    - çŠ¶æ€ç®¡ç†
    """

    name: str = "Manus"
    description: str = "A versatile agent that can solve various tasks using multiple tools including MCP-based tools"

    # ä½¿ç”¨åŠ¨æ€ç³»ç»Ÿæç¤ºè¯
    system_prompt: str = ""
    next_step_prompt: str = ""

    max_observe: int = 10000
    max_steps: int = 20

    # MCP clients for remote tool access
    mcp_clients: MCPClients = Field(default_factory=MCPClients)

    # Add general-purpose tools to the tool collection
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            PythonExecute(),
            BrowserUseTool(),
            StrReplaceEditor(),
            AskHuman(),
            Terminate(),
            CVReaderAgentTool(),
            CVAnalyzerAgentTool(),
            CVOptimizerAgentTool(),
            CVEditorAgentTool(),
            GetResumeStructure(),
        )
    )

    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])
    browser_context_helper: Optional[BrowserContextHelper] = None

    # Track connected MCP servers
    connected_servers: Dict[str, str] = Field(
        default_factory=dict
    )  # server_id -> url/command
    _initialized: bool = False

    # ConversationManager - ä½¿ç”¨ PrivateAttr é¿å… pydantic éªŒè¯
    _conversation_manager: ConversationManager = PrivateAttr(default=None)
    _langchain_memory: LangChainMemoryAdapter = PrivateAttr(default=None)
    _last_intent: Intent = PrivateAttr(default=None)
    _last_intent_info: Dict[str, Any] = PrivateAttr(default_factory=dict)
    _should_wait_user: bool = PrivateAttr(default=False)  # æ˜¯å¦åº”è¯¥ç­‰å¾…ç”¨æˆ·è¾“å…¥
    _current_resume_path: Optional[str] = PrivateAttr(default=None)  # å½“å‰ç®€å†æ–‡ä»¶è·¯å¾„

    @model_validator(mode="after")
    def initialize_helper(self) -> "Manus":
        """Initialize basic components synchronously."""
        self.browser_context_helper = BrowserContextHelper(self)
        # åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨ï¼ˆLLM ä¼šåœ¨ base.py çš„ initialize_agent ä¸­åˆå§‹åŒ–ï¼‰
        # æ³¨æ„ï¼šæ­¤æ—¶ self.llm å¯èƒ½è¿˜æ²¡åˆå§‹åŒ–ï¼Œæ‰€ä»¥å…ˆè®¾ä¸º Noneï¼Œåç»­ä¼šæ›´æ–°
        self._conversation_manager = ConversationManager(llm=None)
        # åˆå§‹åŒ– LangChain Memory
        self._langchain_memory = LangChainMemoryAdapter(k=10, return_messages=True)
        return self

    def _ensure_conversation_manager_llm(self):
        """ç¡®ä¿ ConversationManager æœ‰ LLM å®ä¾‹"""
        if self._conversation_manager and not self._conversation_manager.llm and self.llm:
            self._conversation_manager.llm = self.llm

    @classmethod
    async def create(cls, **kwargs) -> "Manus":
        """Factory method to create and properly initialize a Manus instance."""
        instance = cls(**kwargs)
        await instance.initialize_mcp_servers()
        instance._initialized = True
        return instance

    async def initialize_mcp_servers(self) -> None:
        """Initialize connections to configured MCP servers."""
        for server_id, server_config in config.mcp_config.servers.items():
            try:
                if server_config.type == "sse":
                    if server_config.url:
                        await self.connect_mcp_server(server_config.url, server_id)
                        logger.info(
                            f"Connected to MCP server {server_id} at {server_config.url}"
                        )
                elif server_config.type == "stdio":
                    if server_config.command:
                        await self.connect_mcp_server(
                            server_config.command,
                            server_id,
                            use_stdio=True,
                            stdio_args=server_config.args,
                        )
                        logger.info(
                            f"Connected to MCP server {server_id} using command {server_config.command}"
                        )
            except Exception as e:
                logger.error(f"Failed to connect to MCP server {server_id}: {e}")

    async def connect_mcp_server(
        self,
        server_url: str,
        server_id: str = "",
        use_stdio: bool = False,
        stdio_args: List[str] = None,
    ) -> None:
        """Connect to an MCP server and add its tools."""
        if use_stdio:
            await self.mcp_clients.connect_stdio(
                server_url, stdio_args or [], server_id
            )
            self.connected_servers[server_id or server_url] = server_url
        else:
            await self.mcp_clients.connect_sse(server_url, server_id)
            self.connected_servers[server_id or server_url] = server_url

        # Update available tools with only the new tools from this server
        new_tools = [
            tool for tool in self.mcp_clients.tools if tool.server_id == server_id
        ]
        self.available_tools.add_tools(*new_tools)

    async def disconnect_mcp_server(self, server_id: str = "") -> None:
        """Disconnect from an MCP server and remove its tools."""
        await self.mcp_clients.disconnect(server_id)
        if server_id:
            self.connected_servers.pop(server_id, None)
        else:
            self.connected_servers.clear()

        # Rebuild available tools without the disconnected server's tools
        base_tools = [
            tool
            for tool in self.available_tools.tools
            if not isinstance(tool, MCPClientTool)
        ]
        self.available_tools = ToolCollection(*base_tools)
        self.available_tools.add_tools(*self.mcp_clients.tools)

    async def cleanup(self):
        """Clean up Manus agent resources."""
        if self.browser_context_helper:
            await self.browser_context_helper.cleanup_browser()
        # Disconnect from all MCP servers only if we were initialized
        if self._initialized:
            await self.disconnect_mcp_server()
            self._initialized = False

    def _get_last_user_input(self) -> str:
        """è·å–æœ€åä¸€æ¡çœŸæ­£çš„ç”¨æˆ·è¾“å…¥ï¼ˆè¿‡æ»¤ç³»ç»Ÿæç¤ºè¯ï¼‰"""
        # ç³»ç»Ÿæç¤ºè¯çš„ç‰¹å¾
        system_patterns = [
            "## ",  # Markdown æ ‡é¢˜
            "**é‡è¦",  # é‡è¦æç¤º
            "å·¥å…·é€‰æ‹©",  # å·¥å…·é€‰æ‹©è§„åˆ™
            "æ ¹æ®ç”¨æˆ·è¾“å…¥",  # ç³»ç»ŸæŒ‡ä»¤
            "æ„å›¾è¯†åˆ«",  # ç³»ç»ŸæŒ‡ä»¤
            "cv_reader_agent",  # å·¥å…·å
            "cv_analyzer_agent",
            "cv_optimizer_agent",
        ]

        for msg in reversed(self.memory.messages):
            if msg.role == "user" and msg.content:
                content = msg.content.strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿæç¤ºè¯
                is_system = any(pattern in content for pattern in system_patterns)
                # çœŸæ­£çš„ç”¨æˆ·è¾“å…¥é€šå¸¸è¾ƒçŸ­
                if not is_system and len(content) < 500:
                    return content
        return ""

    async def _generate_dynamic_prompts(self, user_input: str) -> tuple:
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå¯¹è¯çŠ¶æ€åŠ¨æ€ç”Ÿæˆæç¤ºè¯

        ç®€åŒ–ç‰ˆï¼šè®© LLM è‡ªä¸»ç†è§£æ„å›¾å¹¶å†³å®šå·¥å…·è°ƒç”¨

        è¿”å›: (system_prompt, next_step_prompt)
        """
        # ç”Ÿæˆç®€å•çš„ä¸Šä¸‹æ–‡æè¿°
        context_parts = []
        if self._conversation_manager.context.resume_loaded:
            context_parts.append("âœ… ç®€å†å·²åŠ è½½")
        else:
            context_parts.append("âš ï¸ ç®€å†æœªåŠ è½½ï¼Œå»ºè®®å…ˆåŠ è½½ç®€å†")

        # å¦‚æœæœ‰å½“å‰ç®€å†è·¯å¾„ï¼Œæ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        if self._current_resume_path:
            context_parts.append(f"ğŸ“„ å½“å‰ç®€å†æ–‡ä»¶: {self._current_resume_path}")
            context_parts.append("ğŸ’¡ å½“ç”¨æˆ·è¯´'è¯»å–æˆ‘çš„ç®€å†'æˆ–'çœ‹çœ‹æˆ‘çš„ç®€å†'æ—¶ï¼Œåº”è¯¥è¯»å–è¿™ä¸ªæ–‡ä»¶")

        # å¦‚æœæœ‰æ­£åœ¨ä¼˜åŒ–çš„æ¨¡å—ï¼Œç®€å•æç¤º
        if self._conversation_manager.context.optimization.section:
            opt = self._conversation_manager.context.optimization
            context_parts.append(f"æ­£åœ¨ä¼˜åŒ–: {opt.section}")
            if opt.current_question > 0:
                context_parts.append(f"å½“å‰é—®é¢˜: é—®é¢˜{opt.current_question}")

        context = "\n".join(context_parts) if context_parts else "åˆå§‹çŠ¶æ€"

        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆç®€åŒ–ç‰ˆï¼ŒåŒ…å«å·¥å…·åˆ—è¡¨ï¼‰
        system_prompt = SYSTEM_PROMPT.format(
            directory=config.workspace_root,
            context=context
        )

        # ç”Ÿæˆä¸‹ä¸€æ­¥æç¤ºè¯ï¼ˆè®© LLM è‡ªä¸»å†³å®šï¼‰
        next_step = NEXT_STEP_PROMPT

        logger.info(f"ğŸ’­ æç¤ºè¯å·²ç”Ÿæˆï¼Œè®© LLM è‡ªä¸»ç†è§£å’Œå†³ç­–")

        return system_prompt, next_step

    def _generate_intent_hint(self, result: Dict[str, Any]) -> str:
        """æ ¹æ®æ„å›¾è¯†åˆ«ç»“æœç”Ÿæˆæç¤º"""
        intent = result["intent"]
        tool = result.get("tool")
        tool_args = result.get("tool_args", {})

        hints = []

        if intent == Intent.GREETING:
            hints.append("ç”¨æˆ·åœ¨æ‰“æ‹›å‘¼ï¼Œè¯·å‹å¥½å›åº”å¹¶ä»‹ç»ä½ çš„èƒ½åŠ›ã€‚")

        elif intent == Intent.VIEW_RESUME:
            hints.append(f"ç”¨æˆ·æƒ³æŸ¥çœ‹ç®€å†ï¼Œè¯·ä½¿ç”¨ {tool} å·¥å…·ã€‚")

        elif intent == Intent.ANALYZE:
            hints.append(f"ç”¨æˆ·æƒ³åˆ†æç®€å†ï¼Œè¯·ä½¿ç”¨ {tool} å·¥å…·è¿›è¡Œæ·±å…¥åˆ†æã€‚")

        elif intent == Intent.OPTIMIZE:
            hints.append(f"ç”¨æˆ·æƒ³ä¼˜åŒ–ç®€å†ï¼Œè¯·ä½¿ç”¨ {tool} å·¥å…·ã€‚")
            if tool_args:
                hints.append(f"å‚æ•°: {tool_args}")

        elif intent == Intent.OPTIMIZE_SECTION:
            section = tool_args.get("section", "å·¥ä½œç»å†")
            hints.append(f"ç”¨æˆ·æƒ³ä¼˜åŒ– [{section}] æ¨¡å—ã€‚")
            hints.append(f"è¯·è°ƒç”¨: {tool}(action='optimize_section', section='{section}')")

        elif intent == Intent.ANSWER_QUESTION:
            question = tool_args.get("question", "é—®é¢˜1")
            section = tool_args.get("section", "å·¥ä½œç»å†")
            answer = tool_args.get("answer", "")
            hints.append(f"ç”¨æˆ·æ­£åœ¨å›ç­” {question}ã€‚")
            hints.append(f"è¯·è°ƒç”¨: {tool}(action='optimize_section', section='{section}', answer='{answer[:50]}...', question='{question}')")
            hints.append("**é‡è¦**: ç›´æ¥è°ƒç”¨å·¥å…·å¤„ç†å›ç­”ï¼Œä¸è¦é‡æ–°åˆ†æç®€å†ï¼")

        elif intent == Intent.CONFIRM:
            if tool:
                hints.append(f"ç”¨æˆ·ç¡®è®¤äº†æ“ä½œï¼Œè¯·ä½¿ç”¨ {tool} å·¥å…·ç»§ç»­ã€‚")
            else:
                hints.append("ç”¨æˆ·ç¡®è®¤äº†æ“ä½œï¼Œè¯·æ ¹æ®ä¹‹å‰çš„å»ºè®®ç»§ç»­ã€‚")

        else:
            hints.append("æ— æ³•ç¡®å®šç”¨æˆ·æ„å›¾ï¼Œè¯·æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡ç†è§£ç”¨æˆ·éœ€æ±‚ã€‚")
            context_state = self._conversation_manager.context.state
            hints.append(f"å½“å‰çŠ¶æ€: {context_state.value}")

        return "\n".join(hints)

    async def think(self) -> bool:
        """Process current state and decide next actions with intelligent context management."""
        if not self._initialized:
            await self.initialize_mcp_servers()
            self._initialized = True

        # ç¡®ä¿ ConversationManager æœ‰ LLM å®ä¾‹
        self._ensure_conversation_manager_llm()

        # è·å–æœ€åçš„ç”¨æˆ·è¾“å…¥
        user_input = self._get_last_user_input()

        # åŠ¨æ€ç”Ÿæˆæç¤ºè¯ï¼ˆå¼‚æ­¥ï¼‰
        self.system_prompt, self.next_step_prompt = await self._generate_dynamic_prompts(user_input)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æµè§ˆå™¨ä¸Šä¸‹æ–‡
        recent_messages = self.memory.messages[-3:] if self.memory.messages else []
        browser_in_use = any(
            tc.function.name == BrowserUseTool().name
            for msg in recent_messages
            if msg.tool_calls
            for tc in msg.tool_calls
        )

        if browser_in_use:
            browser_prompt = await self.browser_context_helper.format_next_step_prompt()
            self.next_step_prompt = f"{self.next_step_prompt}\n\n{browser_prompt}"

        # è°ƒç”¨çˆ¶ç±»çš„ think æ–¹æ³•
        result = await super().think()

        return result

    async def act(self) -> str:
        """Execute tool calls and update conversation state."""
        result = await super().act()

        # æ›´æ–°å¯¹è¯ç®¡ç†å™¨çŠ¶æ€
        if self.tool_calls:
            for tool_call in self.tool_calls:
                tool_name = tool_call.function.name
                self._conversation_manager.update_after_tool(tool_name, result)

                # ç‰¹æ®Šå¤„ç†ï¼šåŠ è½½ç®€å†åæ›´æ–°çŠ¶æ€
                if "load_resume" in tool_name.lower() or "cv_reader" in tool_name.lower():
                    if "æˆåŠŸ" in result or "åŠ è½½" in result:
                        self._conversation_manager.update_resume_loaded(True)

        # åŒæ­¥æ¶ˆæ¯åˆ° LangChain Memory
        if self._langchain_memory:
            # æ·»åŠ æœ€è¿‘çš„ assistant æ¶ˆæ¯
            for msg in reversed(self.memory.messages[-5:]):
                if msg.role == Role.ASSISTANT and msg.content:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                    langchain_messages = self._langchain_memory.get_messages()
                    if not langchain_messages or langchain_messages[-1].content != msg.content:
                        self._langchain_memory.add_message(msg)
                    break

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç­‰å¾…ç”¨æˆ·è¾“å…¥
        # ä¼˜å…ˆæ£€æŸ¥å·¥å…·è¿”å›çš„ç»“æœï¼ˆå› ä¸ºå·¥å…·å¯èƒ½è¿”å›é—®é¢˜ï¼‰
        if self._langchain_memory:
            # æ£€æŸ¥å·¥å…·è¿”å›çš„ç»“æœï¼ˆresult æ˜¯æ ¼å¼åŒ–åçš„ï¼ŒåŒ…å« "Observed output of cmd..."ï¼‰
            tool_result = result if result else None

            # å¦‚æœå·¥å…·è¿”å›åŒ…å«é—®é¢˜å…³é”®è¯ï¼Œç›´æ¥æ ‡è®°ä¸ºéœ€è¦ç­‰å¾…
            if tool_result:
                wait_keywords = [
                    "é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3", "é—®é¢˜ä¸€", "é—®é¢˜äºŒ", "é—®é¢˜ä¸‰",
                    "è¯·å›ç­”", "æˆ‘å»ºè®®å…ˆå›ç­”", "ç»§ç»­å›ç­”", "æˆ‘æœ€å»ºè®®å…ˆå›ç­”"
                ]
                has_wait_keyword = any(kw in tool_result for kw in wait_keywords)

                # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„ç­‰å¾…æç¤ºï¼ˆä¸æ˜¯é”™è¯¯ä¿¡æ¯ï¼Œé•¿åº¦åˆç†ï¼‰
                if has_wait_keyword and 50 < len(tool_result) < 2000:
                    # ç¡®ä¿ä¸æ˜¯é”™è¯¯ä¿¡æ¯
                    if "error" not in tool_result.lower() and "å¤±è´¥" not in tool_result:
                        self._should_wait_user = True
                        logger.info(f"â¸ï¸ Manus: å·¥å…·è¿”å›åŒ…å«é—®é¢˜ï¼Œéœ€è¦ç­‰å¾…ç”¨æˆ·è¾“å…¥ - {tool_result[:100]}...")
                        return result

            # å¦åˆ™æ£€æŸ¥æœ€åçš„ AI æ¶ˆæ¯
            last_ai_msg = None
            for msg in reversed(self.memory.messages[-3:]):
                if msg.role == Role.ASSISTANT and msg.content:
                    last_ai_msg = msg.content
                    break

            self._should_wait_user = self._langchain_memory.should_wait_for_user(last_ai_msg)
            if self._should_wait_user:
                logger.info("â¸ï¸ Manus: æ£€æµ‹åˆ°éœ€è¦ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œå°†æš‚åœæ‰§è¡Œ")

        return result

    def should_wait_for_user(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ç­‰å¾…ç”¨æˆ·è¾“å…¥"""
        return self._should_wait_user
