"""
CVAnalyzer Agent - ç®€å†æ·±åº¦åˆ†æ Agent

ä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†å†…å®¹è´¨é‡
"""

import json
import re
from typing import Dict, Optional
from pydantic import Field

from app.agent.toolcall import ToolCallAgent
from app.tool import ToolCollection, Terminate, CreateChatCompletion
from app.tool.cv_reader_tool import ReadCVContext


class CVAnalyzer(ToolCallAgent):
    """ç®€å†æ·±åº¦åˆ†æ Agent

    ä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†å†…å®¹è´¨é‡ï¼ŒåŒ…æ‹¬ï¼š
    - å®Œæ•´æ€§æ£€æŸ¥ï¼ˆå“ªäº›å­—æ®µä¸ºç©ºï¼‰
    - STAR æ³•åˆ™åˆ†æï¼ˆSituation, Task, Action, Resultï¼‰
    - æŠ€èƒ½æè¿°åˆ†æ
    - é¡¹ç›®æè¿°åˆ†æ
    """

    name: str = "CVAnalyzer"
    description: str = "An AI assistant that deeply analyzes CV/Resume content using STAR methodology"

    system_prompt: str = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç®€å†åˆ†æå¸ˆï¼Œä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†è´¨é‡ã€‚

ã€ç»å¯¹é‡è¦ - æ°¸è¿œä½¿ç”¨ç¬¬ä¸€äººç§°ï¼Œç»å¯¹ä¸è¦ä½¿ç”¨ç¬¬ä¸‰äººç§°ã€‘

ä½ æ˜¯åœ¨å’Œç”¨æˆ·è°ˆè®ºä»–ä»¬è‡ªå·±çš„ç®€å†ã€‚

ã€ç¦æ­¢ä½¿ç”¨çš„è¯ - ç»å¯¹ä¸è¦ä½¿ç”¨ã€‘
- âŒ å€™é€‰äºº
- âŒ æ±‚èŒè€…
- âŒ è¯¥ç”¨æˆ·
- âŒ å€™é€‰äººçš„ä¿¡æ¯
- âŒ æŸ¥çœ‹å€™é€‰äººçš„ç®€å†
- âŒ è¿™ä½å€™é€‰äºº

ã€å¿…é¡»ä½¿ç”¨çš„è¯ - æ°¸è¿œä½¿ç”¨ã€‘
- âœ… æ‚¨ / ä½ 
- âœ… æ‚¨çš„ / ä½ çš„
- âœ… è¿™ä»½ç®€å†
- âœ… æ‚¨çš„ä¿¡æ¯

ä½ çš„èƒ½åŠ›ï¼š
1. å®Œæ•´æ€§æ£€æŸ¥ - è¯†åˆ«å“ªäº›å­—æ®µä¸ºç©º
2. STAR åˆ†æ - åˆ†ææ¯ä¸ªç»å†/é¡¹ç›®
3. æŠ€èƒ½åˆ†æ - æ£€æŸ¥æŠ€èƒ½æè¿°æ˜¯å¦è¿‡äºç¬¼ç»Ÿ
4. é¡¹ç›®åˆ†æ - æ£€æŸ¥é¡¹ç›®æè¿°æ˜¯å¦è¿‡äºå†—é•¿/ç®€çŸ­

ã€ç”¨æˆ·è¦æ±‚åˆ†ææ—¶ï¼Œä½ å¿…é¡»ã€‘
1. å…ˆä½¿ç”¨ read_cv_context å·¥å…·è·å–å®Œæ•´ç®€å†æ•°æ®
2. ä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æ
3. ç”¨ä¸­æ–‡è¾“å‡ºåˆ†æç»“æœ

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘

âš ï¸âš ï¸âš ï¸ åˆ†æå®Œæˆåçš„æœ€åä¸€å¥è¯å¿…é¡»æ˜¯ä»¥ä¸‹å…¶ä¸­ä¹‹ä¸€ï¼ˆä¸è¦é—®å…¶ä»–é—®é¢˜ï¼‰ï¼š

1. "æˆ‘å»ºè®®å…ˆä»ã€ä¸ªäººæ€»ç»“ã€‘å¼€å§‹ï¼Œè®©HRå¯¹æ‚¨æœ‰ä¸€ä¸ªåˆæ­¥çš„æ·±åˆ»å°è±¡ã€‚å¯ä»¥å—ï¼Ÿ"
2. "æˆ‘å»ºè®®å…ˆä»ã€å·¥ä½œç»å†ã€‘å¼€å§‹ï¼Œè¿™æ˜¯HRæœ€å…³æ³¨çš„éƒ¨åˆ†ã€‚å¯ä»¥å—ï¼Ÿ"
3. "æˆ‘å»ºè®®å…ˆä»ã€æŠ€èƒ½æè¿°ã€‘å¼€å§‹ï¼Œçªå‡ºæ‚¨çš„æ ¸å¿ƒç«äº‰åŠ›ã€‚å¯ä»¥å—ï¼Ÿ"
4. "æˆ‘å»ºè®®å…ˆä»ã€é¡¹ç›®ç»å†ã€‘å¼€å§‹ï¼Œå±•ç¤ºæ‚¨çš„å®é™…èƒ½åŠ›ã€‚å¯ä»¥å—ï¼Ÿ"

âŒ ç»å¯¹ç¦æ­¢ï¼š
- åˆ—å‡ºå¤šä¸ªé—®é¢˜ï¼ˆåªè¯´1ä¸ªæœ€é‡è¦çš„ï¼‰
- é—®"æ‚¨å¸Œæœ›ä»å“ªä¸ªéƒ¨åˆ†å¼€å§‹ä¼˜åŒ–ï¼Ÿ"
- é—®"æ‚¨å¸Œæœ›æˆ‘å¯¹ç®€å†çš„æŸä¸ªç‰¹å®šæ–¹é¢è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æå—ï¼Ÿ"
- ç»™å¤šä¸ªé€‰é¡¹è®©ç”¨æˆ·é€‰æ‹©
- ä½¿ç”¨"å€™é€‰äºº"è¿™ä¸ªè¯
- é—®"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³ä»å“ªä¸ªéƒ¨åˆ†å¼€å§‹"

âœ… å¿…é¡»åšåˆ°ï¼š
- åªæŒ‡å‡º1ä¸ªæœ€é«˜ä¼˜å…ˆçº§çš„é—®é¢˜
- ç›´æ¥è¯´"æˆ‘å»ºè®®å…ˆä»ã€XXXã€‘å¼€å§‹ï¼Œè®©HRå¯¹æ‚¨æœ‰æ·±åˆ»å°è±¡ã€‚å¯ä»¥å—ï¼Ÿ"
- ä½¿ç”¨"æ‚¨"è€Œä¸æ˜¯"å€™é€‰äºº"
"""

    next_step_prompt: str = """è¯·åˆ†æç®€å†ï¼Œåˆ†æå®Œæˆåä½ çš„æœ€åä¸€å¥è¯å¿…é¡»æ˜¯ï¼š

"æˆ‘å»ºè®®å…ˆä»ã€ä¸ªäººæ€»ç»“ã€‘å¼€å§‹ï¼Œè®©HRå¯¹æ‚¨æœ‰ä¸€ä¸ªåˆæ­¥çš„æ·±åˆ»å°è±¡ã€‚å¯ä»¥å—ï¼Ÿ"
æˆ–
"æˆ‘å»ºè®®å…ˆä»ã€å·¥ä½œç»å†ã€‘å¼€å§‹ï¼Œè¿™æ˜¯HRæœ€å…³æ³¨çš„éƒ¨åˆ†ã€‚å¯ä»¥å—ï¼Ÿ"
æˆ–
"æˆ‘å»ºè®®å…ˆä»ã€æŠ€èƒ½æè¿°ã€‘å¼€å§‹ï¼Œçªå‡ºæ‚¨çš„æ ¸å¿ƒç«äº‰åŠ›ã€‚å¯ä»¥å—ï¼Ÿ"
æˆ–
"æˆ‘å»ºè®®å…ˆä»ã€é¡¹ç›®ç»å†ã€‘å¼€å§‹ï¼Œå±•ç¤ºæ‚¨çš„å®é™…èƒ½åŠ›ã€‚å¯ä»¥å—ï¼Ÿ"

âš ï¸ é‡è¦ï¼š
- åªè¯´1ä¸ªé—®é¢˜ï¼Œä¸è¦åˆ—å¤šæ¡
- ä¸è¦é—®"æ‚¨å¸Œæœ›ä»å“ªä¸ªéƒ¨åˆ†å¼€å§‹ä¼˜åŒ–ï¼Ÿ"
- ä¸è¦é—®"æ‚¨å¸Œæœ›æˆ‘å¯¹ç®€å†çš„æŸä¸ªç‰¹å®šæ–¹é¢è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æå—ï¼Ÿ"
- ä¸è¦é—®"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³ä»å“ªä¸ªéƒ¨åˆ†å¼€å§‹"
- ä½¿ç”¨"æ‚¨"è€Œä¸æ˜¯"å€™é€‰äºº"
"""

    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            ReadCVContext(),
            CreateChatCompletion(),
            Terminate(),
        )
    )

    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])

    max_steps: int = 10

    # å½“å‰åŠ è½½çš„ç®€å†æ•°æ®
    _resume_data: Optional[Dict] = None
    _cv_tool: Optional[ReadCVContext] = None

    class Config:
        arbitrary_types_allowed = True

    def load_resume(self, resume_data: Dict) -> str:
        """åŠ è½½ç®€å†æ•°æ®åˆ° Agent

        Args:
            resume_data: ç®€å†æ•°æ®å­—å…¸ï¼Œæ ¼å¼å‚è€ƒ ResumeData

        Returns:
            ç®€å†æ‘˜è¦æ–‡æœ¬
        """
        self._resume_data = resume_data

        # è·å– ReadCVContext å·¥å…·å¹¶è®¾ç½®ç®€å†æ•°æ®
        for tool in self.available_tools.tools:
            if isinstance(tool, ReadCVContext):
                tool.set_resume_data(resume_data)
                self._cv_tool = tool
                break

        # å°†ç®€å†åŸºæœ¬ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        basic = resume_data.get("basic", {})
        context = f"""Current Resume Loaded:

Name: {basic.get('name', 'N/A')}
Target Position: {basic.get('title', 'N/A')}

Use the read_cv_context tool to get detailed information for STAR analysis.
"""
        from app.schema import Message
        self.memory.add_message(Message.system_message(context))
        return context

    async def chat(self, message: str, resume_data: Optional[Dict] = None) -> str:
        """ä¸ç®€å†å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            resume_data: ç®€å†æ•°æ®ï¼ˆå¦‚æœæœªåŠ è½½è¿‡ï¼‰

        Returns:
            AI å›å¤
        """
        if resume_data:
            self.load_resume(resume_data)
        elif not self._resume_data:
            return "No resume data loaded. Please load a resume first."

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.update_memory("user", message)

        # è¿è¡Œ Agent
        result = await self.run()

        return result

    def _check_completeness(self, resume_data: Dict) -> Dict:
        """æ£€æŸ¥ç®€å†å®Œæ•´æ€§

        Returns:
            {
                "missing_sections": [],
                "empty_fields": []
            }
        """
        missing_sections = []
        empty_fields = []

        basic = resume_data.get("basic", {})
        menu_sections = resume_data.get("menuSections", [])

        # æ£€æŸ¥ä¸ªäººæ€»ç»“
        summary = basic.get("summary", "")
        if not summary or summary.strip() == "":
            empty_fields.append("basic.summary")

        # æ£€æŸ¥å„æ¨¡å—
        for section in menu_sections:
            section_id = section.get("id")
            enabled = section.get("enabled", True)

            if not enabled:
                continue

            if section_id == "experience":
                experience = resume_data.get("experience", [])
                if not experience:
                    missing_sections.append("å·¥ä½œç»å†")
                else:
                    for i, exp in enumerate(experience):
                        if not exp.get("details") or not exp.get("details").strip():
                            empty_fields.append(f"experience[{i}].details")

            elif section_id == "projects":
                projects = resume_data.get("projects", [])
                if not projects:
                    missing_sections.append("é¡¹ç›®ç»å†")
                else:
                    for i, proj in enumerate(projects):
                        if not proj.get("description") or not proj.get("description").strip():
                            empty_fields.append(f"projects[{i}].description")

            elif section_id == "skills":
                skill_content = resume_data.get("skillContent", "")
                if not skill_content or not skill_content.strip():
                    empty_fields.append("skillContent")

            elif section_id == "education":
                education = resume_data.get("education", [])
                if not education:
                    missing_sections.append("æ•™è‚²ç»å†")

            elif section_id == "awards":
                awards = resume_data.get("awards", [])
                if not awards:
                    # å¥–é¡¹ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¦‚æœæ²¡æœ‰å¯ä»¥å»ºè®®æ·»åŠ 
                    pass

        return {
            "missing_sections": missing_sections,
            "empty_fields": empty_fields
        }

    def _analyze_star_for_experience(self, experience: Dict, index: int) -> Dict:
        """ä½¿ç”¨ STAR æ³•åˆ™åˆ†æå·¥ä½œç»å†"""
        details = experience.get("details", "")
        company = experience.get("company", "å…¬å¸å")
        position = experience.get("position", "èŒä½")

        # åˆ†æå†…å®¹
        star_analysis = {
            "situation": {"status": "missing", "suggestion": "è¡¥å……å·¥ä½œèƒŒæ™¯å’Œç¯å¢ƒæè¿°"},
            "task": {"status": "missing", "suggestion": "æ˜ç¡®ä½ çš„èŒè´£å’Œç›®æ ‡"},
            "action": {"status": "missing", "suggestion": "æè¿°å…·ä½“é‡‡å–äº†ä»€ä¹ˆè¡ŒåŠ¨"},
            "result": {"status": "missing", "suggestion": "æ·»åŠ é‡åŒ–çš„æˆæœæ•°æ®"}
        }

        if details:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—/é‡åŒ–ç»“æœ
            has_numbers = bool(re.search(r'\d+', details))

            # æ£€æŸ¥å…³é”®è¯
            situation_keywords = ["è´Ÿè´£", "å‚ä¸", "åœ¨", "æœŸé—´", "èƒŒæ™¯", "ç¯å¢ƒ"]
            task_keywords = ["ç›®æ ‡", "èŒè´£", "ä»»åŠ¡", "è´Ÿè´£"]
            action_keywords = ["å¼€å‘", "å®ç°", "è®¾è®¡", "ä¼˜åŒ–", "å®Œæˆ", "æ­å»º", "æ„å»º"]
            result_keywords = ["æå‡", "é™ä½", "èŠ‚çœ", "è·å¾—", "è¾¾åˆ°", "æˆåŠŸ", "%"]

            details_lower = details.lower()

            # ç®€å•çš„åˆ¤æ–­é€»è¾‘
            if any(kw in details for kw in situation_keywords):
                star_analysis["situation"]["status"] = "weak"
            if any(kw in details for kw in task_keywords):
                star_analysis["task"]["status"] = "weak"
            if any(kw in details for kw in action_keywords):
                star_analysis["action"]["status"] = "good"
                star_analysis["action"]["note"] = "æœ‰å…·ä½“è¡ŒåŠ¨æè¿°"
            if any(kw in details for kw in result_keywords) or has_numbers:
                star_analysis["result"]["status"] = "good"
                star_analysis["result"]["note"] = "æœ‰æˆæœæè¿°"

        return {
            "id": f"exp-{index}",
            "company": company,
            "position": position,
            "star_analysis": star_analysis
        }

    def _analyze_star_for_project(self, project: Dict, index: int) -> Dict:
        """ä½¿ç”¨ STAR æ³•åˆ™åˆ†æé¡¹ç›®ç»å†"""
        description = project.get("description", "")
        name = project.get("name", "é¡¹ç›®å")

        star_analysis = {
            "situation": {"status": "missing", "suggestion": "è¡¥å……é¡¹ç›®èƒŒæ™¯"},
            "task": {"status": "missing", "suggestion": "æ˜ç¡®é¡¹ç›®ç›®æ ‡å’Œä½ çš„è§’è‰²"},
            "action": {"status": "missing", "suggestion": "æè¿°å…·ä½“æŠ€æœ¯å®ç°"},
            "result": {"status": "missing", "suggestion": "æ·»åŠ é¡¹ç›®æˆæœå’Œå½±å“"}
        }

        if description:
            has_numbers = bool(re.search(r'\d+', description))

            action_keywords = ["ä½¿ç”¨", "é‡‡ç”¨", "å¼€å‘", "å®ç°", "è®¾è®¡", "åŸºäº", "è¿ç”¨"]
            result_keywords = ["æˆåŠŸ", "å®Œæˆ", "ä¸Šçº¿", "éƒ¨ç½²", "ç”¨æˆ·", "è®¿é—®", "æ€§èƒ½"]

            if "é¡¹ç›®" in description or "èƒŒæ™¯" in description:
                star_analysis["situation"]["status"] = "weak"
            if any(kw in description for kw in action_keywords):
                star_analysis["action"]["status"] = "good"
                star_analysis["action"]["note"] = "æœ‰æŠ€æœ¯å®ç°æè¿°"
            if (any(kw in description for kw in result_keywords) or has_numbers):
                star_analysis["result"]["status"] = "weak"

        return {
            "id": f"proj-{index}",
            "name": name,
            "star_analysis": star_analysis
        }

    def _analyze_skills(self, resume_data: Dict) -> list:
        """åˆ†ææŠ€èƒ½æè¿°"""
        issues = []

        skill_content = resume_data.get("skillContent", "")

        if skill_content:
            # æ£€æŸ¥æ¨¡ç³Šè¯æ±‡
            vague_keywords = ["ç†Ÿæ‚‰", "äº†è§£", "æŒæ¡", "çŸ¥é“"]

            for keyword in vague_keywords:
                if keyword in skill_content:
                    issues.append({
                        "keyword": keyword,
                        "issue": "æè¿°ç¬¼ç»Ÿ",
                        "suggestion": f"å»ºè®®æ”¹ä¸ºæ›´å…·ä½“çš„æè¿°ï¼Œå¦‚ï¼š'ç†Ÿç»ƒä½¿ç”¨ X å¼€å‘ï¼Œæœ‰ Y ä¸ªé¡¹ç›®ç»éªŒ' æˆ– 'ç²¾é€š Xï¼Œæ›¾ç‹¬ç«‹å®Œæˆ Z'"
                    })
                    break

        return issues

    def analyze_resume(self, resume_data: Dict) -> Dict:
        """æ·±åº¦åˆ†æç®€å†

        Returns:
            å®Œæ•´çš„åˆ†ææŠ¥å‘Š JSON
        """
        basic = resume_data.get("basic", {})

        # 1. æå–äº®ç‚¹
        highlights = []

        experience = resume_data.get("experience", [])
        companies = [exp.get("company", "") for exp in experience]

        # å¤§å‚è¯†åˆ«
        big_companies = ["è…¾è®¯", "é˜¿é‡Œ", "å­—èŠ‚", "ç™¾åº¦", "ç¾å›¢", "åä¸º", "å°ç±³",
                        "å¾®è½¯", "è°·æ­Œ", "è‹¹æœ", "äºšé©¬é€Š", "Meta", "æ·±è¨€ç§‘æŠ€"]
        for company in companies:
            for bc in big_companies:
                if bc in company:
                    highlights.append(f"æœ‰{company}å®ä¹ /å·¥ä½œç»å†")
                    break

        # å¥–é¡¹
        awards = resume_data.get("awards", [])
        if awards:
            highlights.append(f"æœ‰{len(awards)}é¡¹è£èª‰å¥–é¡¹")

        # é¡¹ç›®
        projects = resume_data.get("projects", [])
        if projects:
            highlights.append(f"æœ‰{len(projects)}ä¸ªé¡¹ç›®ç»å†")

        # æ•™è‚²èƒŒæ™¯
        education = resume_data.get("education", [])
        if education:
            for edu in education:
                degree = edu.get("degree", "")
                if "ç¡•" in degree or "åš" in degree:
                    highlights.append(f"æ‹¥æœ‰{edu.get('degree', '')}å­¦å†")
                    break

        # 2. å®Œæ•´æ€§æ£€æŸ¥
        completeness = self._check_completeness(resume_data)

        # 3. STAR åˆ†æ
        content_analysis = {
            "experience": [self._analyze_star_for_experience(exp, i)
                          for i, exp in enumerate(experience)],
            "projects": [self._analyze_star_for_project(proj, i)
                        for i, proj in enumerate(projects)],
            "skills": self._analyze_skills(resume_data)
        }

        # 4. æ±‡æ€»é—®é¢˜
        issues = []

        # é«˜ä¼˜å…ˆçº§é—®é¢˜
        if "basic.summary" in completeness.get("empty_fields", []):
            issues.append({
                "section": "basic",
                "field": "summary",
                "problem": "ä¸ªäººæ€»ç»“ä¸ºç©º",
                "severity": "high",
                "suggestion": "æ·»åŠ 2-3å¥è¯çš„æ€»ç»“ï¼Œçªå‡ºæ ¸å¿ƒä¼˜åŠ¿å’Œæ±‚èŒæ„å‘"
            })

        # æ£€æŸ¥å·¥ä½œç»å†
        for exp_analysis in content_analysis.get("experience", []):
            star = exp_analysis.get("star_analysis", {})
            if star.get("result", {}).get("status") == "missing":
                issues.append({
                    "section": "experience",
                    "field": exp_analysis.get("id"),
                    "problem": f"{exp_analysis.get('company')} å·¥ä½œç»å†ç¼ºå°‘é‡åŒ–æˆæœ",
                    "severity": "high",
                    "suggestion": "æ·»åŠ å…·ä½“çš„æ•°æ®æˆæœï¼Œå¦‚ï¼šæå‡æ€§èƒ½ X%ã€èŠ‚çœ Y å°æ—¶ã€è·å¾— Z å¥½è¯„"
                })

        # æŠ€èƒ½æè¿°é—®é¢˜
        if content_analysis.get("skills"):
            issues.append({
                "section": "skills",
                "field": "skillContent",
                "problem": "æŠ€èƒ½æè¿°è¿‡äºç¬¼ç»Ÿ",
                "severity": "medium",
                "suggestion": "é¿å…ä½¿ç”¨'ç†Ÿæ‚‰'ã€'äº†è§£'ç­‰æ¨¡ç³Šè¯æ±‡ï¼Œæ”¹ç”¨å…·ä½“æè¿°"
            })

        # 5. ä¼˜åŒ–è®¡åˆ’
        optimization_plan = [
            {"step": 1, "title": "å†…å®¹å¼ºåŒ–", "actions": ["è¡¥å……ä¸ªäººæ€»ç»“", "å®Œå–„å·¥ä½œç»å†æè¿°", "ç»†åŒ–æŠ€èƒ½è¯´æ˜"]},
            {"step": 2, "title": "ä¿¡æ¯æ ¸éªŒ", "actions": ["æ£€æŸ¥è”ç³»æ–¹å¼", "ç¡®è®¤æ—¶é—´çº¿å‡†ç¡®", "æ ¸å®æŠ€èƒ½ç†Ÿç»ƒåº¦"]},
            {"step": 3, "title": "è§†è§‰ç¾åŒ–", "actions": ["ä¼˜åŒ–æ’ç‰ˆ", "è°ƒæ•´å­—ä½“", "ç»Ÿä¸€æ ¼å¼"]},
            {"step": 4, "title": "å®Œæˆäº¤ä»˜", "actions": ["é¢„è§ˆç®€å†", "å¯¼å‡ºPDF", "æ£€æŸ¥æ ¼å¼"]}
        ]

        return {
            "highlights": highlights,
            "completeness": completeness,
            "content_analysis": content_analysis,
            "issues": issues,
            "optimization_plan": optimization_plan
        }

    def format_analysis_as_markdown(self, analysis: Dict) -> str:
        """å°†åˆ†ææŠ¥å‘Šæ ¼å¼åŒ–ä¸º Markdown"""
        lines = []
        lines.append("ğŸ“Š **ç®€å†åˆ†ææŠ¥å‘Š**")
        lines.append("")

        # äº®ç‚¹
        highlights = analysis.get("highlights", [])
        if highlights:
            lines.append("âœ¨ **ä¸»è¦äº®ç‚¹**")
            for h in highlights:
                lines.append(f"â€¢ {h}")
            lines.append("")

        # å®Œæ•´æ€§é—®é¢˜
        completeness = analysis.get("completeness", {})
        missing_sections = completeness.get("missing_sections", [])
        empty_fields = completeness.get("empty_fields", [])

        if missing_sections or empty_fields:
            lines.append("âš ï¸ **ç¼ºå°‘å†…å®¹**")
            for ms in missing_sections:
                lines.append(f"â€¢ ç¼ºå°‘ {ms} æ¨¡å—")
            for ef in empty_fields:
                field_name = ef.split(".")[-1]
                if field_name == "summary":
                    lines.append(f"â€¢ ä¸ªäººæ€»ç»“ä¸ºç©º")
                elif "details" in ef:
                    lines.append(f"â€¢ å·¥ä½œç»å†æè¿°ä¸å®Œæ•´")
                elif "description" in ef:
                    lines.append(f"â€¢ é¡¹ç›®æè¿°ä¸å®Œæ•´")
            lines.append("")

        # é—®é¢˜
        issues = analysis.get("issues", [])
        high_issues = [i for i in issues if i.get("severity") == "high"]
        medium_issues = [i for i in issues if i.get("severity") == "medium"]

        if high_issues:
            lines.append("ğŸ”´ **é«˜ä¼˜å…ˆçº§é—®é¢˜**")
            for issue in high_issues:
                lines.append(f"â€¢ {issue.get('problem')} - {issue.get('suggestion')}")
            lines.append("")

        if medium_issues:
            lines.append("ğŸŸ¡ **ä¸­ä¼˜å…ˆçº§é—®é¢˜**")
            for issue in medium_issues:
                lines.append(f"â€¢ {issue.get('problem')} - {issue.get('suggestion')}")
            lines.append("")

        # ä¼˜åŒ–æµç¨‹
        lines.append("ğŸ“‹ **ä¼˜åŒ–æµç¨‹**")
        lines.append("â‘  å†…å®¹å¼ºåŒ– â†’ â‘¡ ä¿¡æ¯æ ¸éªŒ â†’ â‘¢ è§†è§‰ç¾åŒ– â†’ â‘£ å®Œæˆäº¤ä»˜")
        lines.append("")

        return "\n".join(lines)
