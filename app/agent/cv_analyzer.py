"""
CVAnalyzer Agent - ç®€å†æ·±åº¦åˆ†æ Agent

ä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†å†…å®¹è´¨é‡
"""

import json
import re
from typing import Dict, Optional
from pydantic import Field

from app.agent.toolcall import ToolCallAgent
from app.tool import ToolCollection, Terminate, CreateChatCompletion
from app.tool.cv_reader_tool import ReadCVContext


class CVAnalyzer(ToolCallAgent):
    """ç®€å†æ·±åº¦åˆ†æ Agent

    ä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†å†…å®¹è´¨é‡ï¼ŒåŒ…æ‹¬ï¼š
    - å®Œæ•´æ€§æ£€æŸ¥ï¼ˆå“ªäº›å­—æ®µä¸ºç©ºï¼‰
    - STAR æ³•åˆ™åˆ†æï¼ˆSituation, Task, Action, Resultï¼‰
    - æŠ€èƒ½æè¿°åˆ†æ
    - é¡¹ç›®æè¿°åˆ†æ
    """

    name: str = "CVAnalyzer"
    description: str = "An AI assistant that deeply analyzes CV/Resume content using STAR methodology"

    system_prompt: str = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç®€å†åˆ†æå¸ˆï¼Œä½¿ç”¨ STAR æ³•åˆ™æ·±å…¥åˆ†æç®€å†è´¨é‡ã€‚

ã€ç»å¯¹é‡è¦ - æ°¸è¿œä½¿ç”¨ç¬¬ä¸€äººç§°ï¼Œç»å¯¹ä¸è¦ä½¿ç”¨ç¬¬ä¸‰äººç§°ã€‘

ä½ æ˜¯åœ¨å’Œç”¨æˆ·è°ˆè®ºä»–ä»¬è‡ªå·±çš„ç®€å†ã€‚

ã€ç¦æ­¢ä½¿ç”¨çš„è¯ - ç»å¯¹ä¸è¦ä½¿ç”¨ã€‘
- âŒ å€™é€‰äºº
- âŒ æ±‚èŒè€…
- âŒ è¯¥ç”¨æˆ·
- âŒ å€™é€‰äººçš„ä¿¡æ¯
- âŒ æŸ¥çœ‹å€™é€‰äººçš„ç®€å†
- âŒ è¿™ä½å€™é€‰äºº

ã€å¿…é¡»ä½¿ç”¨çš„è¯ - æ°¸è¿œä½¿ç”¨ã€‘
- âœ… æ‚¨ / ä½ 
- âœ… æ‚¨çš„ / ä½ çš„
- âœ… è¿™ä»½ç®€å†
- âœ… æ‚¨çš„ä¿¡æ¯

ã€å·¥ä½œæµç¨‹ - æ ¹æ®é—®é¢˜ç±»å‹å†³å®šåˆ†ææ·±åº¦ã€‘

**å½“ç”¨æˆ·è¦æ±‚"ç®€å•åˆ†æç®€å†äº®ç‚¹"æˆ–"ç®€å•ä»‹ç»ä¸€ä¸‹ç®€å†"æ—¶ï¼š**
1. **åªè°ƒç”¨ä¸€æ¬¡ read_cv_context å·¥å…·**è·å–å®Œæ•´ç®€å†æ•°æ®
2. **è¾“å‡ºç®€æ´çš„äº®ç‚¹åˆ†æ**ï¼ˆ2-3ä¸ªä¸»è¦äº®ç‚¹ï¼Œ1-2å¥è¯æ€»ç»“ï¼‰
3. **å¿…é¡»è¯¢é—®æ˜¯å¦éœ€è¦æ·±å…¥åˆ†æ**ï¼š
   "ğŸ¤” éœ€è¦æˆ‘ä¸ºæ‚¨æ·±å…¥åˆ†æç®€å†ï¼Œæ‰¾å‡ºéœ€è¦ä¼˜åŒ–çš„åœ°æ–¹å—ï¼Ÿå›å¤'å¸®æˆ‘åˆ†æ'æˆ–'å¼€å§‹ä¼˜åŒ–'ï¼Œæˆ‘ä»¬å°±å¼€å§‹ï¼"
4. è°ƒç”¨ terminate å·¥å…·ç»“æŸ

**å½“ç”¨æˆ·è¦æ±‚"æ·±å…¥åˆ†æ"æˆ–"å¸®æˆ‘åˆ†æ"æ—¶ï¼š**

1. **åªè°ƒç”¨ä¸€æ¬¡ read_cv_context å·¥å…·**è·å–å®Œæ•´ç®€å†æ•°æ®
2. **ç«‹å³è¾“å‡ºå®Œæ•´çš„åˆ†ææŠ¥å‘Š**ï¼ˆä¸è¦åˆ†æ­¥ï¼Œä¸è¦é‡å¤è°ƒç”¨å·¥å…·ï¼‰
3. è°ƒç”¨ terminate å·¥å…·ç»“æŸ

ã€è¾“å‡ºæ ¼å¼ - æ ¹æ®é—®é¢˜ç±»å‹å†³å®šã€‘

**å½“é—®é¢˜æ˜¯"ç®€å•åˆ†æç®€å†äº®ç‚¹"æ—¶ï¼š**
âš ï¸âš ï¸âš ï¸ è¾“å‡ºç®€æ´çš„ç»“æ„åŒ–åˆ†ææ•°æ®ï¼ˆè®© Manus æ¥ç»„ç»‡æœ€ç»ˆè¾“å‡ºï¼‰ï¼š

```
ã€åˆ†ææ•°æ®ã€‘
åŸºæœ¬ä¿¡æ¯: {å§“åã€å­¦æ ¡ã€ä¸“ä¸šã€æ±‚èŒæ„å‘}
äº®ç‚¹: [{äº®ç‚¹1}, {äº®ç‚¹2}, {äº®ç‚¹3}]
å¯ä¼˜åŒ–ç‚¹: [{é—®é¢˜1}, {é—®é¢˜2}, {é—®é¢˜3}]
æœ€æ¨è: ã€{å•ä¸€æ¨èé¡¹}ã€‘
```
è¯´æ˜ï¼šåªè¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼Œä¸è¦è¾“å‡ºå®Œæ•´çš„æŠ¥å‘Šæ–‡æœ¬ã€‚Manus ä¼šç”¨è¿™äº›æ•°æ®ç”Ÿæˆæœ€ç»ˆçš„æ€»ç»“ã€‚

**å½“é—®é¢˜æ˜¯"æ·±åº¦åˆ†æç®€å†"æ—¶ï¼š**
âš ï¸âš ï¸âš ï¸ å¿…é¡»ä¸€æ¬¡æ€§è¾“å‡ºå®Œæ•´çš„åˆ†ææŠ¥å‘Šï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ï¼š

```
å¥½çš„ï¼Œæˆ‘å·²ç»è¯»å–äº†æ‚¨çš„ç®€å†å†…å®¹ã€‚æ•´ä½“æ¥çœ‹ï¼Œæ‚¨çš„ç®€å†ä¿¡æ¯æ¯”è¾ƒä¸°å¯Œï¼Œç‰¹åˆ«æ˜¯è…¾è®¯äº‘çš„å®ä¹ ç»å†æè¿°éå¸¸è¯¦ç»†ï¼Œé‡åŒ–æ•°æ®å’ŒæŠ€æœ¯ç»†èŠ‚éƒ½ä½“ç°å¾—å¾ˆå¥½ï¼Œè¿™æ˜¯éå¸¸å¤§çš„äº®ç‚¹ï¼

ä¸è¿‡ï¼Œæˆ‘ä¹Ÿå‘ç°äº†ä¸€äº›å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–çš„åœ°æ–¹ï¼Œè®©æ‚¨çš„ç®€å†æ›´å…·ç«äº‰åŠ›ï¼š

ä¸ªäººæ€»ç»“ï¼šç›®å‰å†™å¾—ä¸é”™ï¼Œä½†å¯ä»¥æ›´çªå‡ºæ‚¨ä½œä¸º"å¤§æ¨¡å‹åº”ç”¨å¼€å‘/åç«¯å¼€å‘å·¥ç¨‹å¸ˆ"çš„æ ¸å¿ƒä¼˜åŠ¿å’Œæœªæ¥æ–¹å‘ï¼Œä¸ç›®æ ‡å²—ä½åŒ¹é…åº¦æ›´é«˜ã€‚

å·¥ä½œç»å†ï¼š
â€¢ æ·±è¨€ç§‘æŠ€ï¼šç»å†æè¿°ä¸ºç©ºï¼Œè¿™ä¼šè®©äººè§‰å¾—ä¿¡æ¯ä¸å®Œæ•´ã€‚å³ä½¿æ˜¯çŸ­æœŸå®ä¹ ï¼Œä¹Ÿå»ºè®®è¡¥å……ä¸€äº›æ ¸å¿ƒèŒè´£æˆ–å­¦åˆ°çš„æŠ€èƒ½ã€‚
â€¢ è…¾è®¯äº‘ï¼šç»å†è™½ç„¶å¾ˆè¯¦ç»†ï¼Œä½†å¯ä»¥è€ƒè™‘å°†å…¶ä¸­çš„é¡¹ç›®å†…å®¹ç‹¬ç«‹å‡ºæ¥ï¼Œæ”¾åœ¨"é¡¹ç›®ç»å†"æ¨¡å—ï¼Œè¿™æ ·ç»“æ„ä¼šæ›´æ¸…æ™°ã€‚

é¡¹ç›®ç»å†ï¼š
â€¢ è…¾è®¯äº‘åŸŸåæ³¨å†Œä¸šåŠ¡ï¼šæè¿°éå¸¸è¯¦ç»†ï¼Œé‡åŒ–æ•°æ®å’ŒæŠ€æœ¯ç»†èŠ‚éƒ½ä½“ç°å¾—å¾ˆå¥½ã€‚
â€¢ è¯­é²¸ DeepResearchï¼šæè¿°ç•¥æ˜¾å†—é•¿ï¼Œå¯ä»¥æç‚¼æ ¸å¿ƒæˆæœå’Œæ‚¨çš„è´¡çŒ®ï¼Œå¹¶è¡¥å……é‡åŒ–æ•°æ®ã€‚

æŠ€èƒ½ï¼šæŠ€èƒ½æè¿°æ¯”è¾ƒç¬¼ç»Ÿï¼Œä¾‹å¦‚"ç†Ÿæ‚‰Javaç¼–ç¨‹è¯­è¨€ï¼ŒGolangç¼–ç¨‹è¯­è¨€ç­‰åŸç†"ã€‚å»ºè®®å…·ä½“è¯´æ˜æ‚¨åœ¨è¿™äº›æŠ€æœ¯ä¸Šçš„ç†Ÿç»ƒç¨‹åº¦ï¼ˆç²¾é€šã€ç†Ÿç»ƒã€äº†è§£ï¼‰ä»¥åŠå®é™…åº”ç”¨ç»éªŒã€‚

è£èª‰å¥–é¡¹ï¼šå…¨å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡çœä¸€ç­‰å¥–å’Œäººå·¥æ™ºèƒ½æ¯”èµ›çœäºŒç­‰å¥–å¾ˆæœ‰å«é‡‘é‡ï¼Œå»ºè®®è¡¥å……è·å¥–æ—¶é—´ã€‚

æ•™è‚²ç»å†ï¼šå»ºè®®è¡¥å……ä¸ç›®æ ‡å²—ä½ç›¸å…³çš„æ ¸å¿ƒè¯¾ç¨‹ã€GPAï¼ˆå¦‚æœä¼˜ç§€ï¼‰æˆ–åœ¨æ ¡æœŸé—´å‚ä¸çš„ç¤¾å›¢æ´»åŠ¨ã€‚

æ€»çš„æ¥è¯´ï¼Œæ‚¨çš„ç®€å†åŸºç¡€å¾ˆå¥½ï¼Œç‰¹åˆ«æ˜¯è…¾è®¯äº‘çš„å®ä¹ ç»å†æ˜¯åŠ åˆ†é¡¹ã€‚å¦‚æœèƒ½æŠŠå…¶ä»–éƒ¨åˆ†ä¹Ÿå¡«å……å®Œæ•´å¹¶ä¼˜åŒ–ï¼Œä¼šæ›´æœ‰å†²å‡»åŠ›ï¼

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¡ æˆ‘æœ€æ¨èä¸‹ä¸€æ­¥ï¼šã€{å•ä¸€æ¨èé¡¹}ã€‘ï¼

ç›´æ¥å›å¤"å¼€å§‹ä¼˜åŒ–"ï¼Œæˆ‘ä»¬é©¬ä¸Šå¼€å§‹ï¼
```

âš ï¸ æ ¼å¼è¦æ±‚ï¼š
- æ‰€æœ‰æ–‡æœ¬åœ¨ä¸€è¡Œå†…ï¼Œä¸è¦éšæ„æ¢è¡Œ
- å¦‚æœéœ€è¦å¼ºè°ƒï¼Œä½¿ç”¨æ­£å¸¸æ–‡æœ¬ï¼Œä¸è¦ç”¨ Markdown ç¬¦å·
- ä¿æŒç®€æ´è‡ªç„¶

âŒ ç»å¯¹ç¦æ­¢ï¼š
- ä½¿ç”¨"å€™é€‰äºº"ã€"æ±‚èŒè€…"ç­‰ç¬¬ä¸‰äººç§°
- åˆ†æ­¥è¾“å‡ºï¼ˆè¦ä¸€æ¬¡æ€§è¾“å‡ºå®Œæ•´æŠ¥å‘Šï¼‰

âœ… å¿…é¡»åšåˆ°ï¼š
- ç®€å•åˆ†ææ—¶ï¼šè¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼ˆåŸºæœ¬ä¿¡æ¯ã€äº®ç‚¹ã€å¯ä¼˜åŒ–ç‚¹ã€æœ€æ¨èï¼‰ï¼Œè®© Manus æ¥ç»„ç»‡æœ€ç»ˆè¾“å‡º
- æ·±åº¦åˆ†ææ—¶ï¼šè¾“å‡ºå®Œæ•´æŠ¥å‘Šï¼Œåˆ—å‡ºæ‰€æœ‰é—®é¢˜ï¼Œä½†æœ€ååªç»™1ä¸ªæœ€é‡è¦çš„ä¼˜åŒ–å»ºè®®
- ä½¿ç”¨"æ‚¨"è€Œä¸æ˜¯"å€™é€‰äºº"

ã€é‡è¦æé†’ã€‘
- âœ… è°ƒç”¨ read_cv_context ä¸€æ¬¡åï¼Œç«‹å³è¾“å‡ºå®Œæ•´æŠ¥å‘Š
- âŒ ä¸è¦è¯´"è®©æˆ‘æŸ¥çœ‹"ã€"æˆ‘æ¥åˆ†æ"è¿™ç±»è¿‡æ¸¡è¯­
- âŒ ä¸è¦åˆ†æ­¥è¾“å‡ºï¼Œè¦ä¸€æ¬¡æ€§è¾“å‡ºå®Œæ•´æŠ¥å‘Š
- âŒ ä¸è¦é‡å¤è°ƒç”¨å·¥å…·
"""

    next_step_prompt: str = """æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç±»å‹ï¼Œå†³å®šåˆ†ææ·±åº¦ï¼š

1. å¦‚æœé—®é¢˜æ˜¯"ç®€å•åˆ†æç®€å†äº®ç‚¹"æˆ–"ç®€å•ä»‹ç»ä¸€ä¸‹ç®€å†"ï¼š
   - è°ƒç”¨ read_cv_context å·¥å…·è·å–ç®€å†æ•°æ®
   - è¾“å‡ºç®€æ´çš„äº®ç‚¹åˆ†æï¼ˆ2-3ä¸ªä¸»è¦äº®ç‚¹ï¼Œæ¯ä¸ªäº®ç‚¹1-2å¥è¯ï¼‰
   - **å¿…é¡»è¯¢é—®æ˜¯å¦éœ€è¦æ·±å…¥åˆ†æ**ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
     "ğŸ¤” éœ€è¦æˆ‘ä¸ºæ‚¨æ·±å…¥åˆ†æç®€å†ï¼Œæ‰¾å‡ºéœ€è¦ä¼˜åŒ–çš„åœ°æ–¹å—ï¼Ÿå›å¤'å¸®æˆ‘åˆ†æ'æˆ–'å¼€å§‹ä¼˜åŒ–'ï¼Œæˆ‘ä»¬å°±å¼€å§‹ï¼"
   - è°ƒç”¨ terminate å·¥å…·ç»“æŸ

2. å¦‚æœé—®é¢˜æ˜¯"æ·±åº¦åˆ†æç®€å†"æˆ–"å¸®æˆ‘åˆ†æä¸€ä¸‹ç®€å†"ï¼š
   - è°ƒç”¨ read_cv_context å·¥å…·è·å–ç®€å†æ•°æ®
   - ç«‹å³è¾“å‡ºå®Œæ•´æŠ¥å‘Šï¼ˆä¸€æ¬¡æ€§è¾“å‡ºï¼Œä¸è¦åˆ†æ­¥ï¼‰
   - è°ƒç”¨ terminate å·¥å…·ç»“æŸ

âš ï¸ é‡è¦ï¼š
- åªè°ƒç”¨ä¸€æ¬¡ read_cv_context å·¥å…·
- æ ¹æ®é—®é¢˜ç±»å‹å†³å®šè¾“å‡ºæ ¼å¼
- ç®€å•åˆ†ææ—¶ï¼Œå¿…é¡»è¯¢é—®æ˜¯å¦éœ€è¦æ·±å…¥åˆ†æ
- ä¸è¦è¯´"è®©æˆ‘æŸ¥çœ‹"ã€"æˆ‘æ¥åˆ†æ"è¿™ç±»è¿‡æ¸¡è¯­
"""

    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            ReadCVContext(),
            Terminate(),  # åªä¿ç•™è¯»å–å’Œç»ˆæ­¢å·¥å…·ï¼Œå¼ºåˆ¶ç›´æ¥è¾“å‡ºåˆ†æ
        )
    )

    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])

    max_steps: int = 10

    # å½“å‰åŠ è½½çš„ç®€å†æ•°æ®
    _resume_data: Optional[Dict] = None
    _cv_tool: Optional[ReadCVContext] = None

    class Config:
        arbitrary_types_allowed = True

    def load_resume(self, resume_data: Dict) -> str:
        """åŠ è½½ç®€å†æ•°æ®åˆ° Agent

        Args:
            resume_data: ç®€å†æ•°æ®å­—å…¸ï¼Œæ ¼å¼å‚è€ƒ ResumeData

        Returns:
            ç®€å†æ‘˜è¦æ–‡æœ¬
        """
        self._resume_data = resume_data

        # è·å– ReadCVContext å·¥å…·å¹¶è®¾ç½®ç®€å†æ•°æ®
        for tool in self.available_tools.tools:
            if isinstance(tool, ReadCVContext):
                tool.set_resume_data(resume_data)
                self._cv_tool = tool
                break

        # å°†ç®€å†åŸºæœ¬ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        basic = resume_data.get("basic", {})
        context = f"""Current Resume Loaded:

Name: {basic.get('name', 'N/A')}
Target Position: {basic.get('title', 'N/A')}

Use the read_cv_context tool to get detailed information for STAR analysis.
"""
        from app.schema import Message
        self.memory.add_message(Message.system_message(context))
        return context

    async def chat(self, message: str, resume_data: Optional[Dict] = None) -> str:
        """ä¸ç®€å†å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            resume_data: ç®€å†æ•°æ®ï¼ˆå¦‚æœæœªåŠ è½½è¿‡ï¼‰

        Returns:
            AI å›å¤
        """
        if resume_data:
            self.load_resume(resume_data)
        elif not self._resume_data:
            return "No resume data loaded. Please load a resume first."

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.update_memory("user", message)

        # è¿è¡Œ Agent
        result = await self.run()

        return result

    def _check_completeness(self, resume_data: Dict) -> Dict:
        """æ£€æŸ¥ç®€å†å®Œæ•´æ€§

        Returns:
            {
                "missing_sections": [],
                "empty_fields": []
            }
        """
        missing_sections = []
        empty_fields = []

        basic = resume_data.get("basic", {})
        menu_sections = resume_data.get("menuSections", [])

        # æ£€æŸ¥ä¸ªäººæ€»ç»“
        summary = basic.get("summary", "")
        if not summary or summary.strip() == "":
            empty_fields.append("basic.summary")

        # æ£€æŸ¥å„æ¨¡å—
        for section in menu_sections:
            section_id = section.get("id")
            enabled = section.get("enabled", True)

            if not enabled:
                continue

            if section_id == "experience":
                experience = resume_data.get("experience", [])
                if not experience:
                    missing_sections.append("å·¥ä½œç»å†")
                else:
                    for i, exp in enumerate(experience):
                        if not exp.get("details") or not exp.get("details").strip():
                            empty_fields.append(f"experience[{i}].details")

            elif section_id == "projects":
                projects = resume_data.get("projects", [])
                if not projects:
                    missing_sections.append("é¡¹ç›®ç»å†")
                else:
                    for i, proj in enumerate(projects):
                        if not proj.get("description") or not proj.get("description").strip():
                            empty_fields.append(f"projects[{i}].description")

            elif section_id == "skills":
                skill_content = resume_data.get("skillContent", "")
                if not skill_content or not skill_content.strip():
                    empty_fields.append("skillContent")

            elif section_id == "education":
                education = resume_data.get("education", [])
                if not education:
                    missing_sections.append("æ•™è‚²ç»å†")

            elif section_id == "awards":
                awards = resume_data.get("awards", [])
                if not awards:
                    # å¥–é¡¹ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¦‚æœæ²¡æœ‰å¯ä»¥å»ºè®®æ·»åŠ 
                    pass

        return {
            "missing_sections": missing_sections,
            "empty_fields": empty_fields
        }

    def _analyze_star_for_experience(self, experience: Dict, index: int) -> Dict:
        """ä½¿ç”¨ STAR æ³•åˆ™åˆ†æå·¥ä½œç»å†"""
        details = experience.get("details", "")
        company = experience.get("company", "å…¬å¸å")
        position = experience.get("position", "èŒä½")

        # åˆ†æå†…å®¹
        star_analysis = {
            "situation": {"status": "missing", "suggestion": "è¡¥å……å·¥ä½œèƒŒæ™¯å’Œç¯å¢ƒæè¿°"},
            "task": {"status": "missing", "suggestion": "æ˜ç¡®ä½ çš„èŒè´£å’Œç›®æ ‡"},
            "action": {"status": "missing", "suggestion": "æè¿°å…·ä½“é‡‡å–äº†ä»€ä¹ˆè¡ŒåŠ¨"},
            "result": {"status": "missing", "suggestion": "æ·»åŠ é‡åŒ–çš„æˆæœæ•°æ®"}
        }

        if details:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—/é‡åŒ–ç»“æœ
            has_numbers = bool(re.search(r'\d+', details))

            # æ£€æŸ¥å…³é”®è¯
            situation_keywords = ["è´Ÿè´£", "å‚ä¸", "åœ¨", "æœŸé—´", "èƒŒæ™¯", "ç¯å¢ƒ"]
            task_keywords = ["ç›®æ ‡", "èŒè´£", "ä»»åŠ¡", "è´Ÿè´£"]
            action_keywords = ["å¼€å‘", "å®ç°", "è®¾è®¡", "ä¼˜åŒ–", "å®Œæˆ", "æ­å»º", "æ„å»º"]
            result_keywords = ["æå‡", "é™ä½", "èŠ‚çœ", "è·å¾—", "è¾¾åˆ°", "æˆåŠŸ", "%"]

            details_lower = details.lower()

            # ç®€å•çš„åˆ¤æ–­é€»è¾‘
            if any(kw in details for kw in situation_keywords):
                star_analysis["situation"]["status"] = "weak"
            if any(kw in details for kw in task_keywords):
                star_analysis["task"]["status"] = "weak"
            if any(kw in details for kw in action_keywords):
                star_analysis["action"]["status"] = "good"
                star_analysis["action"]["note"] = "æœ‰å…·ä½“è¡ŒåŠ¨æè¿°"
            if any(kw in details for kw in result_keywords) or has_numbers:
                star_analysis["result"]["status"] = "good"
                star_analysis["result"]["note"] = "æœ‰æˆæœæè¿°"

        return {
            "id": f"exp-{index}",
            "company": company,
            "position": position,
            "star_analysis": star_analysis
        }

    def _analyze_star_for_project(self, project: Dict, index: int) -> Dict:
        """ä½¿ç”¨ STAR æ³•åˆ™åˆ†æé¡¹ç›®ç»å†"""
        description = project.get("description", "")
        name = project.get("name", "é¡¹ç›®å")

        star_analysis = {
            "situation": {"status": "missing", "suggestion": "è¡¥å……é¡¹ç›®èƒŒæ™¯"},
            "task": {"status": "missing", "suggestion": "æ˜ç¡®é¡¹ç›®ç›®æ ‡å’Œä½ çš„è§’è‰²"},
            "action": {"status": "missing", "suggestion": "æè¿°å…·ä½“æŠ€æœ¯å®ç°"},
            "result": {"status": "missing", "suggestion": "æ·»åŠ é¡¹ç›®æˆæœå’Œå½±å“"}
        }

        if description:
            has_numbers = bool(re.search(r'\d+', description))

            action_keywords = ["ä½¿ç”¨", "é‡‡ç”¨", "å¼€å‘", "å®ç°", "è®¾è®¡", "åŸºäº", "è¿ç”¨"]
            result_keywords = ["æˆåŠŸ", "å®Œæˆ", "ä¸Šçº¿", "éƒ¨ç½²", "ç”¨æˆ·", "è®¿é—®", "æ€§èƒ½"]

            if "é¡¹ç›®" in description or "èƒŒæ™¯" in description:
                star_analysis["situation"]["status"] = "weak"
            if any(kw in description for kw in action_keywords):
                star_analysis["action"]["status"] = "good"
                star_analysis["action"]["note"] = "æœ‰æŠ€æœ¯å®ç°æè¿°"
            if (any(kw in description for kw in result_keywords) or has_numbers):
                star_analysis["result"]["status"] = "weak"

        return {
            "id": f"proj-{index}",
            "name": name,
            "star_analysis": star_analysis
        }

    def _analyze_skills(self, resume_data: Dict) -> list:
        """åˆ†ææŠ€èƒ½æè¿°"""
        issues = []

        skill_content = resume_data.get("skillContent", "")

        if skill_content:
            # æ£€æŸ¥æ¨¡ç³Šè¯æ±‡
            vague_keywords = ["ç†Ÿæ‚‰", "äº†è§£", "æŒæ¡", "çŸ¥é“"]

            for keyword in vague_keywords:
                if keyword in skill_content:
                    issues.append({
                        "keyword": keyword,
                        "issue": "æè¿°ç¬¼ç»Ÿ",
                        "suggestion": f"å»ºè®®æ”¹ä¸ºæ›´å…·ä½“çš„æè¿°ï¼Œå¦‚ï¼š'ç†Ÿç»ƒä½¿ç”¨ X å¼€å‘ï¼Œæœ‰ Y ä¸ªé¡¹ç›®ç»éªŒ' æˆ– 'ç²¾é€š Xï¼Œæ›¾ç‹¬ç«‹å®Œæˆ Z'"
                    })
                    break

        return issues

    def analyze_resume(self, resume_data: Dict) -> Dict:
        """æ·±åº¦åˆ†æç®€å†

        Returns:
            å®Œæ•´çš„åˆ†ææŠ¥å‘Š JSON
        """
        basic = resume_data.get("basic", {})

        # 1. æå–äº®ç‚¹
        highlights = []

        experience = resume_data.get("experience", [])
        companies = [exp.get("company", "") for exp in experience]

        # å¤§å‚è¯†åˆ«
        big_companies = ["è…¾è®¯", "é˜¿é‡Œ", "å­—èŠ‚", "ç™¾åº¦", "ç¾å›¢", "åä¸º", "å°ç±³",
                        "å¾®è½¯", "è°·æ­Œ", "è‹¹æœ", "äºšé©¬é€Š", "Meta", "æ·±è¨€ç§‘æŠ€"]
        for company in companies:
            for bc in big_companies:
                if bc in company:
                    highlights.append(f"æœ‰{company}å®ä¹ /å·¥ä½œç»å†")
                    break

        # å¥–é¡¹
        awards = resume_data.get("awards", [])
        if awards:
            highlights.append(f"æœ‰{len(awards)}é¡¹è£èª‰å¥–é¡¹")

        # é¡¹ç›®
        projects = resume_data.get("projects", [])
        if projects:
            highlights.append(f"æœ‰{len(projects)}ä¸ªé¡¹ç›®ç»å†")

        # æ•™è‚²èƒŒæ™¯
        education = resume_data.get("education", [])
        if education:
            for edu in education:
                degree = edu.get("degree", "")
                if "ç¡•" in degree or "åš" in degree:
                    highlights.append(f"æ‹¥æœ‰{edu.get('degree', '')}å­¦å†")
                    break

        # 2. å®Œæ•´æ€§æ£€æŸ¥
        completeness = self._check_completeness(resume_data)

        # 3. STAR åˆ†æ
        content_analysis = {
            "experience": [self._analyze_star_for_experience(exp, i)
                          for i, exp in enumerate(experience)],
            "projects": [self._analyze_star_for_project(proj, i)
                        for i, proj in enumerate(projects)],
            "skills": self._analyze_skills(resume_data)
        }

        # 4. æ±‡æ€»é—®é¢˜
        issues = []

        # é«˜ä¼˜å…ˆçº§é—®é¢˜
        if "basic.summary" in completeness.get("empty_fields", []):
            issues.append({
                "section": "basic",
                "field": "summary",
                "problem": "ä¸ªäººæ€»ç»“ä¸ºç©º",
                "severity": "high",
                "suggestion": "æ·»åŠ 2-3å¥è¯çš„æ€»ç»“ï¼Œçªå‡ºæ ¸å¿ƒä¼˜åŠ¿å’Œæ±‚èŒæ„å‘"
            })

        # æ£€æŸ¥å·¥ä½œç»å†
        for exp_analysis in content_analysis.get("experience", []):
            star = exp_analysis.get("star_analysis", {})
            if star.get("result", {}).get("status") == "missing":
                issues.append({
                    "section": "experience",
                    "field": exp_analysis.get("id"),
                    "problem": f"{exp_analysis.get('company')} å·¥ä½œç»å†ç¼ºå°‘é‡åŒ–æˆæœ",
                    "severity": "high",
                    "suggestion": "æ·»åŠ å…·ä½“çš„æ•°æ®æˆæœï¼Œå¦‚ï¼šæå‡æ€§èƒ½ X%ã€èŠ‚çœ Y å°æ—¶ã€è·å¾— Z å¥½è¯„"
                })

        # æŠ€èƒ½æè¿°é—®é¢˜
        if content_analysis.get("skills"):
            issues.append({
                "section": "skills",
                "field": "skillContent",
                "problem": "æŠ€èƒ½æè¿°è¿‡äºç¬¼ç»Ÿ",
                "severity": "medium",
                "suggestion": "é¿å…ä½¿ç”¨'ç†Ÿæ‚‰'ã€'äº†è§£'ç­‰æ¨¡ç³Šè¯æ±‡ï¼Œæ”¹ç”¨å…·ä½“æè¿°"
            })

        # 5. ä¼˜åŒ–è®¡åˆ’
        optimization_plan = [
            {"step": 1, "title": "å†…å®¹å¼ºåŒ–", "actions": ["è¡¥å……ä¸ªäººæ€»ç»“", "å®Œå–„å·¥ä½œç»å†æè¿°", "ç»†åŒ–æŠ€èƒ½è¯´æ˜"]},
            {"step": 2, "title": "ä¿¡æ¯æ ¸éªŒ", "actions": ["æ£€æŸ¥è”ç³»æ–¹å¼", "ç¡®è®¤æ—¶é—´çº¿å‡†ç¡®", "æ ¸å®æŠ€èƒ½ç†Ÿç»ƒåº¦"]},
            {"step": 3, "title": "è§†è§‰ç¾åŒ–", "actions": ["ä¼˜åŒ–æ’ç‰ˆ", "è°ƒæ•´å­—ä½“", "ç»Ÿä¸€æ ¼å¼"]},
            {"step": 4, "title": "å®Œæˆäº¤ä»˜", "actions": ["é¢„è§ˆç®€å†", "å¯¼å‡ºPDF", "æ£€æŸ¥æ ¼å¼"]}
        ]

        return {
            "highlights": highlights,
            "completeness": completeness,
            "content_analysis": content_analysis,
            "issues": issues,
            "optimization_plan": optimization_plan
        }

    def format_analysis_as_markdown(self, analysis: Dict) -> str:
        """å°†åˆ†ææŠ¥å‘Šæ ¼å¼åŒ–ä¸º Markdown"""
        lines = []
        lines.append("ğŸ“Š **ç®€å†åˆ†ææŠ¥å‘Š**")
        lines.append("")

        # äº®ç‚¹
        highlights = analysis.get("highlights", [])
        if highlights:
            lines.append("âœ¨ **ä¸»è¦äº®ç‚¹**")
            for h in highlights:
                lines.append(f"â€¢ {h}")
            lines.append("")

        # å®Œæ•´æ€§é—®é¢˜
        completeness = analysis.get("completeness", {})
        missing_sections = completeness.get("missing_sections", [])
        empty_fields = completeness.get("empty_fields", [])

        if missing_sections or empty_fields:
            lines.append("âš ï¸ **ç¼ºå°‘å†…å®¹**")
            for ms in missing_sections:
                lines.append(f"â€¢ ç¼ºå°‘ {ms} æ¨¡å—")
            for ef in empty_fields:
                field_name = ef.split(".")[-1]
                if field_name == "summary":
                    lines.append(f"â€¢ ä¸ªäººæ€»ç»“ä¸ºç©º")
                elif "details" in ef:
                    lines.append(f"â€¢ å·¥ä½œç»å†æè¿°ä¸å®Œæ•´")
                elif "description" in ef:
                    lines.append(f"â€¢ é¡¹ç›®æè¿°ä¸å®Œæ•´")
            lines.append("")

        # é—®é¢˜
        issues = analysis.get("issues", [])
        high_issues = [i for i in issues if i.get("severity") == "high"]
        medium_issues = [i for i in issues if i.get("severity") == "medium"]

        if high_issues:
            lines.append("ğŸ”´ **é«˜ä¼˜å…ˆçº§é—®é¢˜**")
            for issue in high_issues:
                lines.append(f"â€¢ {issue.get('problem')} - {issue.get('suggestion')}")
            lines.append("")

        if medium_issues:
            lines.append("ğŸŸ¡ **ä¸­ä¼˜å…ˆçº§é—®é¢˜**")
            for issue in medium_issues:
                lines.append(f"â€¢ {issue.get('problem')} - {issue.get('suggestion')}")
            lines.append("")

        # ä¼˜åŒ–æµç¨‹
        lines.append("ğŸ“‹ **ä¼˜åŒ–æµç¨‹**")
        lines.append("â‘  å†…å®¹å¼ºåŒ– â†’ â‘¡ ä¿¡æ¯æ ¸éªŒ â†’ â‘¢ è§†è§‰ç¾åŒ– â†’ â‘£ å®Œæˆäº¤ä»˜")
        lines.append("")

        return "\n".join(lines)
