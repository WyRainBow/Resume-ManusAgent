# 统一上下文管理设计

## 1. 问题本质

### 核心问题定义

在多 Agent 系统中，以下四个概念实际上是同一个问题的不同表现：

- **多 Agent 协同**：多个智能体如何协作完成复杂任务
- **上下文共享**：如何在智能体之间传递和共享信息
- **会话管理**：如何维护多轮对话的状态
- **多轮对话**：如何保持对话的连贯性和上下文

**本质问题**：如何在多个智能体之间维护和传递对话状态（Unified Context Management）。

### 为什么这是个问题

1. **状态碎片化**：每个 Agent 维护自己的状态，导致信息孤岛
2. **上下文丢失**：多轮对话中，早期信息被遗忘或无法访问
3. **协作困难**：Agent 之间缺乏有效的信息传递机制
4. **可追溯性差**：无法追踪决策过程和信息来源
5. **扩展性弱**：添加新 Agent 时难以集成到现有系统

### 理想状态

一个统一的上下文管理系统应该实现：

```
┌─────────────────────────────────────────┐
│         统一上下文存储 (Shared Context)   │
├─────────────────────────────────────────┤
│  - 对话历史 (Conversation History)        │
│  - 用户信息 (User Profile)               │
│  - 任务状态 (Task State)                 │
│  - Agent 输出 (Agent Outputs)            │
│  - 共享记忆 (Shared Memory)              │
└─────────────────────────────────────────┘
           ↑           ↓           ↑
    ┌──────┴──────┐   ┌───┴───┐   └──────┐
    │ Agent A     │   │Agent B│   │Agent C│
    └─────────────┘   └───────┘   └───────┘
```

---

## 2. 开源方案对比

### 2.1 对比总览

| 框架 | 核心概念 | 状态管理 | 记忆类型 | 共享机制 | 优势 | 劣势 |
|------|---------|---------|---------|---------|------|------|
| **LangChain/LangGraph** | Checkpoint + Store | 图状态 + Checkpoint | 短期(对话) + 长期(知识库) | 通过 thread_id 和 user_id | 成熟稳定，生产级支持 | 配置复杂，学习曲线陡 |
| **AutoGen** | Memory Protocol | Agent 内部 model_context | ListMemory, VectorMemory | Memory 注入到 Agent | 轻量级，易于扩展 | Agent 间共享较弱 |
| **CrewAI** | Shared Memory | Crew 级别的状态共享 | 短期 + 实体 + 长期 | 自动在 Crew 内传递 | 声明式，简洁 | 隔离性差，全局污染 |
| **Semantic Kernel** | ChatHistory + KernelContext | ChatHistory Reducer | 截断 + 摘要 | Kernel 对象传递 | 灵活的缩减策略 | 手动管理较多 |
| **Haystack** | Component Pipeline | 组件间数据流 | 会话级 | Pipeline 连接 | 可视化流程 | 重状态，调试困难 |

### 2.2 详细分析

#### LangChain/LangGraph

**核心设计**：
```
┌─────────────────────────────────────┐
│  Graph (StateGraph)                 │
│  ├── State (状态定义)               │
│  └── Nodes (处理节点)               │
└─────────────────────────────────────┘
           ↓
┌─────────────────────────────────────┐
│  Checkpointer (短期记忆)            │
│  ├── thread_id (会话ID)             │
│  └── checkpoint (状态快照)          │
└─────────────────────────────────────┘
           ↓
┌─────────────────────────────────────┐
│  Store (长期记忆)                   │
│  ├── namespace (命名空间)           │
│  └── semantic search (语义搜索)     │
└─────────────────────────────────────┘
```

**关键特性**：
- **Checkpoint**：自动保存图的状态，支持时间旅行（回溯到任意历史点）
- **Store**：跨会话的持久化记忆，支持语义搜索
- **thread_id**：隔离不同会话的短期记忆
- **user_id**：跨会话共享长期记忆

**设计思路**：
1. 短期记忆通过 Checkpointer 实现，每次状态变化自动保存
2. 长期记忆通过 Store 实现，按 namespace 组织
3. 通过 `config` 参数传递 thread_id 和 user_id
4. 支持子图，父图的 checkpointer 自动传播到子图

**为什么这样做**：
- **分离关注点**：短期对话状态和长期知识分离
- **时间旅行**：Checkpoint 允许调试和回溯
- **可扩展性**：支持多种数据库（Postgres, Redis, MongoDB）

---

#### AutoGen

**核心设计**：
```
┌─────────────────────────────────────┐
│  Memory Protocol                    │
│  ├── add()          添加记忆        │
│  ├── query()        检索记忆        │
│  ├── update_context() 注入上下文    │
│  ├── clear()        清空记忆        │
│  └── close()        释放资源        │
└─────────────────────────────────────┘
           ↓
┌─────────────────────────────────────┐
│  Memory 实现                        │
│  ├── ListMemory      简单列表       │
│  ├── ChromaDBVectorMemory 向量检索  │
│  ├── RedisMemory     Redis 持久化   │
│  └── Mem0Memory      Mem0.ai 集成   │
└─────────────────────────────────────┘
```

**关键特性**：
- **协议驱动**：定义统一的 Memory 接口，可自定义实现
- **自动注入**：Memory 自动查询并更新 Agent 的 model_context
- **向量检索**：支持语义相似度搜索
- **RAG 集成**：天然支持检索增强生成

**设计思路**：
1. 每个 Agent 可以有多个 Memory 实例
2. 每次运行前，Memory 自动查询相关信息
3. 查询结果作为 System Message 注入到上下文
4. 支持持久化（Redis, ChromaDB）和内存模式

**为什么这样做**：
- **灵活性**：协议接口允许自定义 Memory 实现
- **自动化**：减少手动管理上下文的代码
- **RAG 原生**：向量数据库集成开箱即用

---

#### CrewAI

**核心设计**：
```
┌─────────────────────────────────────┐
│  Crew (团队)                        │
│  ├── Agents (多个智能体)            │
│  ├── Tasks (任务序列)               │
│  └── Shared Memory (共享记忆)       │
└─────────────────────────────────────┘
           ↓
┌─────────────────────────────────────┐
│  Memory Types                       │
│  ├── Short-term:  当前会话          │
│  ├── Entity:    实体提取和记忆      │
│  └── Long-term: 跨会话持久化        │
└─────────────────────────────────────┘
```

**关键特性**：
- **自动传递**：Context 自动在 Task 之间传递
- **声明式配置**：通过 YAML 定义 Agent 和 Task
- **内存管理**：`respect_context_window` 自动处理超长上下文
- **实体记忆**：自动提取和记忆实体（人名、地点等）

**设计思路**：
1. Crew 是顶级容器，包含所有 Agent 和 Task
2. Task 的输出自动成为下一个 Task 的输入
3. Memory 在 Crew 级别共享，所有 Agent 可访问
4. 支持层级 Crew（嵌套团队）

**为什么这样做**：
- **简化开发**：声明式配置减少代码量
- **自动协调**：框架自动处理 Task 依赖
- **智能缩减**：自动处理 Token 限制

---

#### Semantic Kernel

**核心设计**：
```
┌─────────────────────────────────────┐
│  Kernel                             │
│  ├── Plugins (插件/工具)            │
│  ├── ChatHistory (对话历史)         │
│  └── Data (自定义状态字典)          │
└─────────────────────────────────────┘
           ↓
┌─────────────────────────────────────┐
│  ChatHistoryReducer                 │
│  ├── TruncationReducer   截断策略   │
│  └── SummarizationReducer 摘要策略  │
└─────────────────────────────────────┘
```

**关键特性**：
- **Kernel 对象**：中央协调器，携带所有状态
- **ChatHistory**：灵活的对话历史管理
- **Reducer**：智能缩减策略（截断或摘要）
- **Data 字典**：自定义状态存储

**设计思路**：
1. Kernel 在整个应用生命周期中传递
2. ChatHistory 记录所有对话消息
3. Reducer 自动管理历史长度（避免超限）
4. Data 字典存储任意自定义状态

**为什么这样做**：
- **灵活性**：Data 字典允许任意状态
- **智能缩减**：自动处理上下文窗口限制
- **中央化**：Kernel 作为单一事实来源

---

### 2.3 设计思路总结

| 框架 | 状态存储 | 传递方式 | 缩减策略 | 持久化 |
|------|---------|---------|---------|--------|
| LangGraph | Graph State + Checkpoint | 通过 config (thread_id, user_id) | 手动 trim/delete/summarize | 数据库（Postgres, Redis, MongoDB） |
| AutoGen | Agent.model_context | Memory 自动注入 | 无（依赖 LLM 上下文窗口） | 向量数据库（ChromaDB, Redis, Mem0） |
| CrewAI | Crew 级别共享状态 | Task 依赖自动传递 | 自动 respect_context_window | 长期记忆（需配置） |
| Semantic Kernel | Kernel.ChatHistory + Data | Kernel 对象传递 | Reducer（截断/摘要） | 需自行实现 |

---

## 3. 核心设计模式

通过对比上述方案，提炼出以下通用设计模式：

### 3.1 模式一：中央状态存储（Centralized State Store）

**核心思想**：
- 所有 Agent 共享同一个状态存储
- 状态存储是唯一的"事实来源"（Single Source of Truth）

**实现方式**：
```
┌─────────────────────────────────────┐
│  CentralContextStore                │
│  ├── conversations: Map<id, State>  │
│  ├── user_profiles: Map<id, Profile>│
│  └── shared_memory: Memory          │
└─────────────────────────────────────┘
           ↑
    ┌──────┴──────┬─────────┬─────────┐
    │             │         │         │
Agent A        Agent B   Agent C   Agent D
```

**优点**：
- 简单直观
- 易于调试（所有状态在一处）
- 天然支持共享

**缺点**：
- 单点故障风险
- 可能成为性能瓶颈

**代表框架**：CrewAI, Semantic Kernel

---

### 3.2 模式二：消息传递（Message Passing）

**核心思想**：
- Agent 之间通过消息通信
- 状态隐式地在消息流中传递

**实现方式**：
```
Agent A ──message──> Agent B ──message──> Agent C
   ↑                       ↓                ↓
   └──────── context ──────┴──────── context ┘
```

**优点**：
- 解耦（Agent 不直接依赖状态存储）
- 灵活（易于添加新 Agent）
- 符合分布式系统理念

**缺点**：
- 消息可能过大（包含完整上下文）
- 难以追踪全局状态

**代表框架**：AutoGen

---

### 3.3 模式三：检查点机制（Checkpointing）

**核心思想**：
- 定期保存系统状态快照
- 支持时间旅行（回溯）

**实现方式**：
```
┌─────────────────────────────────────┐
│  Time                               │
│  t0 → t1 → t2 → t3 → t4             │
│  ↓    ↓    ↓    ↓    ↓              │
│  CP0  CP1  CP2  CP3  CP4            │
└─────────────────────────────────────┘

回溯到 t2: state = load(CP2)
```

**优点**：
- 支持调试和回溯
- 容错（可以从检查点恢复）
- 可审计（完整历史记录）

**缺点**：
- 存储开销大
- 实现复杂

**代表框架**：LangGraph

---

### 3.4 模式四：双层记忆（Dual-layer Memory）

**核心思想**：
- 短期记忆：当前会话的上下文
- 长期记忆：跨会话的知识库

**实现方式**：
```
┌─────────────────────────────────────┐
│  Agent                              │
│  ├── Short-term (对话历史)          │
│  │   ├── 当前会话消息               │
│  │   └── 自动缩减/摘要              │
│  └── Long-term (知识库)             │
│      ├── 向量数据库                 │
│      └── 语义检索                   │
└─────────────────────────────────────┘
```

**优点**：
- 符合人类记忆模式
- 平衡性能和智能
- 灵活的检索策略

**缺点**：
- 需要管理两个存储系统
- 检索策略可能复杂

**代表框架**：LangGraph, AutoGen, CrewAI

---

### 3.5 模式五：上下文缩减（Context Reduction）

**核心思想**：
- 主动管理上下文大小
- 在超限前智能缩减

**策略对比**：

| 策略 | 原理 | 优点 | 缺点 | 适用场景 |
|------|------|------|------|---------|
| **截断** | 删除最早的消息 | 简单快速 | 信息丢失 | 实时对话 |
| **摘要** | 用 LLM 生成摘要 | 保留关键信息 | 成本高 | 复杂任务 |
| **滑动窗口** | 只保留最近 N 条 | 可预测 | 可能丢失重要信息 | 固定模式对话 |
| **语义过滤** | 保留相关消息 | 智能保留 | 需要向量检索 | 长文档分析 |

**实现流程**：
```
1. 检测上下文大小
   ↓
2. 判断是否需要缩减
   ↓
3. 选择缩减策略
   ↓
4. 执行缩减
   ↓
5. 更新上下文
```

**代表框架**：Semantic Kernel, CrewAI

---

## 4. 推荐方案：针对简历优化项目

### 4.1 项目特点分析

简历优化项目的特殊需求：

1. **多轮对话**：用户可能多次交互，逐步完善简历
2. **多 Agent 协作**：
   - 读取 Agent（解析简历）
   - 分析 Agent（分析问题）
   - 优化 Agent（提出建议）
   - 编辑 Agent（修改简历）
3. **状态复杂**：
   - 原始简历内容
   - 解析后的结构化数据
   - 用户的偏好和目标
   - 历史修改记录
4. **会话持久化**：用户可能多次访问

### 4.2 推荐架构：混合模式

结合 LangGraph 的 Checkpoint + AutoGen 的 Memory + 语义检索

```
┌──────────────────────────────────────────────┐
│            Frontend (用户界面)                │
└──────────────────────────────────────────────┘
                    ↓
┌──────────────────────────────────────────────┐
│         API Layer (FastAPI)                  │
│  ├── /chat (多轮对话)                        │
│  ├── /upload (上传简历)                      │
│  └── /optimize (优化请求)                    │
└──────────────────────────────────────────────┘
                    ↓
┌──────────────────────────────────────────────┐
│       Context Manager (统一上下文管理)        │
│  ├── SessionManager (会话管理)               │
│  │   ├── create_session()                    │
│  │   ├── get_session(session_id)             │
│  │   └── list_sessions(user_id)              │
│  ├── ConversationHistory (对话历史)          │
│  │   ├── add_message(session_id, msg)        │
│  │   ├── get_history(session_id)             │
│  │   └── summarize(session_id)               │
│  └── SharedMemory (共享记忆)                 │
│      ├── resume_data (简历数据)              │
│      ├── user_preferences (用户偏好)         │
│      └── optimization_history (优化记录)     │
└──────────────────────────────────────────────┘
                    ↓
┌──────────────────────────────────────────────┐
│         Agent Orchestration Layer            │
│  ├── CV Reader Agent                         │
│  ├── CV Analyzer Agent                       │
│  ├── CV Optimizer Agent                      │
│  └── CV Editor Agent                         │
└──────────────────────────────────────────────┘
                    ↓
┌──────────────────────────────────────────────┐
│          Storage Layer                       │
│  ├── SQLite (会话和对话历史)                 │
│  ├── Vector Store (语义记忆)                 │
│  └── File System (简历文件)                  │
└──────────────────────────────────────────────┘
```

### 4.3 数据结构设计

#### Session（会话）

```yaml
session:
  id: "uuid"
  user_id: "user_123"
  created_at: "2025-01-03T10:00:00Z"
  updated_at: "2025-01-03T11:30:00Z"
  status: "active" | "completed"
  metadata:
    resume_file: "resume_123.pdf"
    job_target: "Software Engineer"
    industry: "Tech"
```

#### ConversationHistory（对话历史）

```yaml
messages:
  - id: "msg_001"
    session_id: "session_uuid"
    role: "user" | "assistant" | "system"
    content: "请帮我优化这份简历"
    timestamp: "2025-01-03T10:05:00Z"
    agent_source: "cv_analyzer"  # 哪个 Agent 产生的
    metadata:
      tokens: 150
      model: "gpt-4"
```

#### SharedMemory（共享记忆）

```yaml
shared_memory:
  resume_data:
    raw_text: "原始简历内容"
    parsed_sections:
      - name: "工作经历"
        items: [...]
      - name: "教育背景"
        items: [...]
    entities:
      - type: "skill"
        value: "Python"
        confidence: 0.95
      - type: "company"
        value: "Google"
        confidence: 0.98

  user_preferences:
    target_role: "Senior Software Engineer"
    target_companies: ["Google", "Meta", "OpenAI"]
    key_skills_to_highlight: ["LLM", "Python", "System Design"]
    tone: "professional" | "casual"

  optimization_history:
    - timestamp: "2025-01-03T10:10:00Z"
      agent: "cv_analyzer"
      action: "analyze"
      input: "原始简历"
      output: "分析结果"
      suggestions: ["建议量化工作成果", "缺少项目链接"]

    - timestamp: "2025-01-03T10:20:00Z"
      agent: "cv_optimizer"
      action: "optimize"
      input: "分析结果"
      output: "优化建议"
      changes: ["添加了量化指标", "补充了项目链接"]
```

### 4.4 上下文传递流程

```
用户发送消息
    ↓
API 创建/获取 Session
    ↓
ContextManager：
  1. 从 SQLite 加载对话历史
  2. 从 Vector Store 检索相关记忆
  3. 构建完整的上下文
    ↓
传递给 Agent Orchestrator
    ↓
Agent Orchestrator：
  1. 根据意图选择 Agent
  2. 注入上下文到 Agent
  3. 执行 Agent 逻辑
    ↓
Agent 处理并返回结果
    ↓
ContextManager：
  1. 保存新的消息到历史
  2. 更新共享记忆（如果有新信息）
  3. 检查是否需要缩减上下文
    ↓
返回结果给用户
```

### 4.5 上下文缩减策略

针对简历优化项目的混合策略：

1. **分层保留**：
   - 最近 10 条消息：完整保留
   - 10-50 条：保留摘要
   - 50 条以上：只保留关键决策点

2. **智能摘要**：
   ```
   用户上传了简历 → Agent 解析 → 发现问题 A, B, C →
   Agent 提出建议 → 用户修改 → 优化完成
   ```

3. **关键信息永不删除**：
   - 简历原始数据
   - 用户的明确偏好
   - 重要的修改决策

### 4.6 为什么选择这个方案

| 需求 | 解决方案 | 理由 |
|------|---------|------|
| **多轮对话** | Session + ConversationHistory | 明确的会话隔离，支持断点续传 |
| **多 Agent 协作** | SharedMemory | 所有 Agent 访问同一状态，避免重复解析 |
| **状态复杂** | 结构化 SharedMemory | 清晰的数据组织，易于扩展 |
| **会话持久化** | SQLite + 检查点 | 轻量级数据库，支持时间旅行 |
| **语义检索** | Vector Store | 快速检索相关历史建议 |
| **上下文缩减** | 分层保留 + 智能摘要 | 平衡信息完整性和 Token 使用 |

---

## 5. 实施步骤

### 阶段一：基础架构（1-2周）

**目标**：建立核心的上下文管理系统

1. **设计数据模型**
   - Session 表结构
   - Message 表结构
   - SharedMemory schema

2. **实现 ContextManager**
   - `create_session()`
   - `get_session()`
   - `add_message()`
   - `get_history()`

3. **集成到现有系统**
   - 修改 `app/web/server.py`，添加 ContextManager
   - 修改各 Agent Tool，接收 session_id

**验收标准**：
- 可以创建和管理会话
- 对话历史正确保存
- 可以查询历史记录

---

### 阶段二：共享记忆（1周）

**目标**：实现 Agent 之间的状态共享

1. **设计 SharedMemory 结构**
   - 简历数据格式
   - 用户偏好格式
   - 优化历史格式

2. **实现 Memory Manager**
   - `update_resume_data()`
   - `get_user_preferences()`
   - `add_optimization_record()`

3. **修改 Agent**
   - 所有 Agent 从 SharedMemory 读取状态
   - 处理结果写回 SharedMemory

**验收标准**：
- CV Reader 解析后，其他 Agent 能直接使用
- 用户偏好在整个会话中保持
- 优化历史可追溯

---

### 阶段三：上下文缩减（1周）

**目标**：实现智能的上下文管理

1. **实现 Token 计数**
   - 统计当前上下文大小
   - 预警机制

2. **实现缩减策略**
   - 分层保留逻辑
   - 自动摘要生成
   - 关键信息保护

3. **集成到对话流程**
   - 每次添加消息时检查
   - 超限时自动缩减

**验收标准**：
- 长对话不会超限
- 关键信息不丢失
- 摘要质量可接受

---

### 阶段四：语义检索（可选，1-2周）

**目标**：增强记忆检索能力

1. **选择向量数据库**
   - ChromaDB（轻量级）
   - 或 Qdrant（生产级）

2. **实现向量化**
   - 消息嵌入
   - 记忆嵌入

3. **实现语义检索**
   - 根据当前查询检索相关历史
   - 自动注入到上下文

**验收标准**：
- 可以检索相关历史建议
- 检索结果相关度高
- 响应时间可接受

---

### 阶段五：优化和监控（持续）

**目标**：提升性能和可维护性

1. **性能优化**
   - 数据库索引
   - 缓存策略
   - 异步处理

2. **监控和日志**
   - 上下文大小监控
   - Token 使用统计
   - Agent 性能指标

3. **测试**
   - 单元测试
   - 集成测试
   - 压力测试

---

## 6. 总结

### 核心要点

1. **统一问题**：多 Agent 协同、上下文共享、会话管理、多轮对话本质上是同一个问题——统一上下文管理

2. **开源方案**：
   - LangGraph：生产级，检查点机制强大
   - AutoGen：轻量灵活，Memory 协议优雅
   - CrewAI：声明式，自动协调
   - Semantic Kernel：灵活的缩减策略

3. **设计模式**：
   - 中央状态存储
   - 消息传递
   - 检查点机制
   - 双层记忆
   - 上下文缩减

4. **推荐方案**：
   - 混合模式，结合各框架优点
   - Session + ConversationHistory + SharedMemory
   - 分层保留 + 智能摘要

5. **实施计划**：
   - 4-5 个阶段，逐步推进
   - 优先实现基础架构
   - 可选的语义检索

### 关键决策原则

| 决策点 | 建议 | 原因 |
|--------|------|------|
| **状态存储** | 中央化 + SQLite | 简单、可靠、易于调试 |
| **上下文缩减** | 混合策略（分层+摘要） | 平衡性能和信息完整性 |
| **Agent 通信** | 共享内存 + 消息传递 | 兼顾协作和灵活 |
| **持久化** | SQLite + 文件系统 | 轻量级，无需额外依赖 |
| **语义检索** | 可选，后期添加 | 非核心功能，可渐进式实现 |

### 未来扩展

1. **多用户支持**：在 user_id 级别隔离
2. **团队协作**：支持多人编辑同一简历
3. **版本控制**：简历修改的 Git 风格管理
4. **实时同步**：WebSocket 支持
5. **分布式部署**：从单体迁移到微服务

---

## 附录：参考资源

### 官方文档

- [LangGraph Memory Documentation](https://docs.langchain.com/oss/python/langgraph/add-memory)
- [AutoGen Memory and RAG](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/memory.html)
- [CrewAI Agents Documentation](https://docs.crewai.com/en/concepts/agents)
- [Semantic Kernel Python Context Management](https://devblogs.microsoft.com/semantic-kernel/semantic-kernel-python-context-management/)

### 社区资源

- [CrewAI Memory Discussions](https://community.crewai.com/)
- [AutoGen GitHub Issues](https://github.com/microsoft/autogen/discussions)
- [LangGraph State Management Guide](https://sparkco.ai/blog/mastering-langgraph-state-management-in-2025)

### 相关论文

- "Communicative Agents for Software Development"
- "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"
- "AutoGen: Enabling Next-Gen LLM Applications"

---

**文档版本**：v1.0
**创建日期**：2025-01-03
**作者**：Claude (Sonnet 4.5)
**项目**：OpenManus 简历优化系统
