# 上下文传递机制分析

**日期**: 2026-01-06
**类型**: 架构分析
**影响范围**: `app/agent/`, `app/memory/`, `app/llm.py`

---

## 目录

1. [架构概览](#架构概览)
2. [LLM 调用时的上下文传递](#llm-调用时的上下文传递)
3. [Agent 工具结果保存机制](#agent-工具结果保存机制)
4. [动态 Prompt 生成](#动态-prompt-生成)
5. [未来动态 Prompt 设计](#未来动态-prompt-设计)

---

## 架构概览

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        上下文传递架构                                     │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  用户输入 → Manus.think() → LLM.ask_tool() → LLM 响应                   │
│      ↓            ↓                  ↓              ↓                   │
│  ┌─────────┐ ┌─────────┐      ┌──────────┐  ┌──────────┐               │
│  │意图识别  │ │动态Prompt│      │格式化消息  │  │工具调用   │               │
│  └─────────┘ └─────────┘      └──────────┘  └──────────┘               │
│      ↓            ↓                  ↓              ↓                   │
│  ConversationStateManager  →  Memory.messages  →  OpenAI API           │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**核心组件关系**：

```
┌─────────────────────────────────────────────────────────────────┐
│  BaseAgent                                                       │
│  ├── memory: Memory (运行时，50条消息)                           │
│  ├── llm: LLM                                                   │
│  └── messages (property) → self.memory.messages                 │
└─────────────────────────────────────────────────────────────────┘
         ↓ 继承
┌─────────────────────────────────────────────────────────────────┐
│  ToolCallAgent                                                   │
│  ├── think() → 调用 LLM.ask_tool()                              │
│  ├── act() → 执行工具调用                                        │
│  └── available_tools: ToolCollection                            │
└─────────────────────────────────────────────────────────────────┘
         ↓ 继承
┌─────────────────────────────────────────────────────────────────┐
│  Manus                                                           │
│  ├── _conversation_state: ConversationStateManager               │
│  ├── _chat_history: ChatHistoryManager (持久化，30条)            │
│  └── _generate_dynamic_prompts() → 动态生成 system_prompt       │
└─────────────────────────────────────────────────────────────────┘
```

---

## LLM 调用时的上下文传递

### 完整调用链路

```
┌──────────────────────────────────────────────────────────────────────────┐
│  1. Manus.think()                                                       │
│     └── _generate_dynamic_prompts(user_input, intent)                   │
│         ├── system_prompt = SYSTEM_PROMPT.format(context=...)           │
│         └── next_step_prompt = _generate_next_step_prompt(intent)       │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  2. ToolCallAgent.think() (父类)                                        │
│     ├── if _should_add_next_step_prompt():                              │
│     │     └── self.messages += [Message.user_message(next_step_prompt)] │
│     └── response = await self.llm.ask_tool(                             │
│            messages=self.messages,         # ✅ 完整对话历史             │
│            system_msgs=[...],              # ✅ 动态 system prompt       │
│            tools=available_tools.to_params(),                           │
│            tool_choice=ToolChoice.AUTO                                  │
│        )                                                                │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  3. LLM.ask_tool()                                                      │
│     ├── messages = format_messages(messages, supports_images)           │
│     ├── token_count = count_message_tokens(messages)                    │
│     └── response = await client.chat.completions.create(                │
│            model=self.model,                                            │
│            messages=messages,  # ✅ 格式化后的完整消息                   │
│            tools=tools,                                                 │
│            tool_choice=tool_choice                                      │
│        )                                                                │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  4. LLM.format_messages() - 关键上下文转换                              │
│     └── 保留所有消息:                                                   │
│         ├── system → 系统指令（包含当前状态）                           │
│         ├── user → 用户输入                                             │
│         ├── assistant + tool_calls → AI 决策的工具调用                  │
│         └── tool → 工具执行结果（通过 tool_call_id 关联）               │
└──────────────────────────────────────────────────────────────────────────┘
```

### 详细代码分析

#### 1. Manus.think() - 动态 Prompt 生成入口

**文件**: [app/agent/manus.py:330-420](app/agent/manus.py#L330-L420)

```python
async def think(self) -> bool:
    # 1. 意图识别（带上下文）
    intent_result = await self._conversation_state.process_input(
        user_input=user_input,
        conversation_history=self.memory.messages[-5:],  # ✅ 最近5条消息
        last_ai_message=self._get_last_ai_message()
    )

    # 2. 动态生成 Prompt
    self.system_prompt, self.next_step_prompt = await self._generate_dynamic_prompts(
        user_input, intent
    )

    # 3. 调用父类 think（会传递完整消息历史）
    return await super().think()
```

#### 2. ToolCallAgent.think() - 消息历史传递

**文件**: [app/agent/toolcall.py:99-207](app/agent/toolcall.py#L99-L207)

```python
async def think(self) -> bool:
    # 1. 添加 next_step_prompt（带去重）
    if self._should_add_next_step_prompt():
        user_msg = Message.user_message(self.next_step_prompt)
        self.messages += [user_msg]  # ✅ 添加到消息历史

    # 2. 调用 LLM，传入完整上下文
    response = await self.llm.ask_tool(
        messages=self.messages,              # ✅ self.messages = self.memory.messages
        system_msgs=[                        # ✅ 动态生成的 system prompt
            Message.system_message(self.system_prompt)
            if self.system_prompt else None
        ],
        tools=self.available_tools.to_params(),  # ✅ 工具定义
        tool_choice=self.tool_choices,
    )

    # 3. 解析响应
    self.tool_calls = response.tool_calls if response and response.tool_calls else []
    content = response.content if response and response.content else ""

    # 4. 添加 assistant 消息到 memory
    assistant_msg = Message.from_tool_calls(content=content, tool_calls=self.tool_calls)
    self.memory.add_message(assistant_msg)  # ✅ 保存到 memory

    # 5. 自动终止判断
    if self.tool_choices == ToolChoice.AUTO and not self.tool_calls:
        if self.should_auto_terminate(content, tool_calls):
            self.state = AgentState.FINISHED
            return False

    return bool(self.tool_calls)
```

#### 3. LLM.format_messages() - 上下文格式化

**文件**: [app/llm.py:266-393](app/llm.py#L266-L393)

```python
def format_messages(messages: List[Union[dict, Message]], ...) -> List[dict]:
    """
    复刻 LangChain 上下文机制：
    1. 保留所有 AIMessage（含 tool_calls）
    2. 保留所有 ToolMessage（通过 tool_call_id 关联）
    3. LLM 能看到完整的工具调用历史，避免重复调用工具
    """
    formatted_messages = []

    for message in messages:
        if isinstance(message, Message):
            message = message.to_dict()

        # ✅ 保留规则
        if (
            ("content" in message and message["content"])
            or message.get("tool_calls")
            or message.get("role") == "tool"  # ✅ 关键：保留 tool 消息
        ):
            formatted_messages.append(message)

    return formatted_messages
```

### 消息保留规则

| 角色 | 保留条件 | 目的 | 示例 |
|------|----------|------|------|
| `system` | 总是保留 | 系统指令，包含当前状态 | "简历已加载，当前目录：/workspace" |
| `user` | 有内容 | 用户原始输入 | "我是哪个大学的" |
| `assistant` | 有内容或 tool_calls | AI 回答 + 工具调用决策 | `{content: "我来帮你分析", tool_calls: [...]}` |
| `tool` | 通过 tool_call_id 匹配 | **工具执行结果** | `{role: "tool", content: "中山大学", tool_call_id: "call_123"}` |

### 上下文传递的关键设计

1. **完整性保证**: tool 消息必须保留，否则 LLM 无法看到工具执行结果
2. **关联机制**: tool 消息通过 `tool_call_id` 与 assistant 的 tool_calls 关联
3. **去重机制**: `_should_add_next_step_prompt()` 避免重复添加相同 prompt
4. **滑动窗口**: Memory 最多保留 50 条消息，自动裁剪

---

## Agent 工具结果保存机制

### 工具调用完整生命周期

```
┌──────────────────────────────────────────────────────────────────────────┐
│  阶段1: LLM 决策调用工具                                                  │
├──────────────────────────────────────────────────────────────────────────┤
│  LLM 返回:                                                               │
│  {                                                                       │
│    "role": "assistant",                                                  │
│    "content": "我来帮您加载简历",                                         │
│    "tool_calls": [{                                                      │
│      "id": "call_abc123",                                                │
│      "type": "function",                                                 │
│      "function": {                                                       │
│        "name": "cv_reader_agent",                                        │
│        "arguments": '{"file_path": "/path/to/resume.md"}'                │
│      }                                                                   │
│    }]                                                                    │
│  }                                                                       │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  阶段2: ToolCallAgent 保存 assistant 消息                                │
├──────────────────────────────────────────────────────────────────────────┤
│  assistant_msg = Message.from_tool_calls(                                │
│      content="我来帮您加载简历",                                          │
│      tool_calls=[...]                                                    │
│  )                                                                       │
│  self.memory.add_message(assistant_msg)  # ✅ 保存到 memory              │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  阶段3: ToolCallAgent.act() 执行工具                                     │
├──────────────────────────────────────────────────────────────────────────┤
│  for command in self.tool_calls:                                        │
│      result = await self.execute_tool(command)                          │
│      # result = "CV/Resume Context:\nBasic Information: ..."            │
│                                                                          │
│      # ✅ 关键：保存工具执行结果                                         │
│      tool_msg = Message.tool_message(                                   │
│          content=result,                                                │
│          tool_call_id=command.id,  # ✅ 关联 tool_call                  │
│          name=command.function.name                                     │
│      )                                                                   │
│      self.memory.add_message(tool_msg)  # ✅ 保存到 memory              │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  阶段4: 下一次 LLM 调用可以看到完整历史                                   │
├──────────────────────────────────────────────────────────────────────────┤
│  messages = [                                                            │
│    {role: "user", content: "加载简历"},                                 │
│    {role: "assistant", content: "...", tool_calls: [...]},              │
│    {role: "tool", content: "CV/Resume Context: ...",                    │
│                     tool_call_id: "call_abc123", name: "cv_reader_agent"}│
│  ]                                                                       │
│                                                                          │
│  ✅ LLM 可以看到工具执行结果，基于结果继续对话                           │
└──────────────────────────────────────────────────────────────────────────┘
```

### 代码实现

**文件**: [app/agent/toolcall.py:209-242](app/agent/toolcall.py#L209-L242)

```python
async def act(self) -> str:
    """Execute tool calls and handle their results"""
    results = []

    for command in self.tool_calls:
        # 执行工具
        result = await self.execute_tool(command)

        # ✅ 关键：保存工具执行结果到 memory
        tool_msg = Message.tool_message(
            content=result,
            tool_call_id=command.id,     # ✅ 与 tool_call 关联
            name=command.function.name,
            base64_image=self._current_base64_image,
        )
        self.memory.add_message(tool_msg)  # ✅ 保存
        results.append(result)

    return "\n\n".join(results)
```

### 工具结果保存的关键点

| 组件 | 作用 | 关键代码 |
|------|------|----------|
| `tool_call_id` | 关联 assistant 的 tool_calls 和 tool 结果 | `Message.tool_message(..., tool_call_id=command.id)` |
| `memory.add_message()` | 保存到运行时 memory | `self.memory.add_message(tool_msg)` |
| `format_messages()` | 确保工具结果被传递给 LLM | 保留 `role == "tool"` 的消息 |
| `cleanup_incomplete_sequences()` | 清理不完整的序列 | 删除 orphaned tool 消息 |

### ChatHistory 持久化

**文件**: [app/web/streaming/agent_stream.py:348-378](app/web/streaming/agent_stream.py#L348-L378)

```python
# 执行完成后，保存到 ChatHistory（持久化）
if self._chat_history_manager:
    # 保存用户消息
    user_msg = Message(role=Role.USER, content=user_message)
    self._chat_history_manager.add_message(user_msg)

    # 保存所有 agent 生成的消息
    for msg in self.agent.memory.messages:
        if msg.role == Role.ASSISTANT:
            self._chat_history_manager.add_message(Message(
                role=Role.ASSISTANT,
                content=msg.content,
                tool_calls=msg.tool_calls
            ))
        elif msg.role == Role.TOOL:
            # ✅ 关键：保存 tool 消息（包含 optimization_suggestions JSON）
            self._chat_history_manager.add_message(Message(
                role=Role.TOOL,
                content=msg.content,
                name=msg.name,
                tool_call_id=msg.tool_call_id
            ))
```

---

## 动态 Prompt 生成

### 当前实现架构

```
┌──────────────────────────────────────────────────────────────────────────┐
│  _generate_dynamic_prompts(user_input, intent)                           │
├──────────────────────────────────────────────────────────────────────────┤
│  输入:                                                                   │
│  ├── user_input: 用户原始输入                                            │
│  ├── intent: 意图识别结果 (GREETING/LOAD_RESUME/UNKNOWN)                │
│  ├── self._conversation_state.context: 对话状态                          │
│  └── self._current_resume_path: 当前简历路径                            │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  system_prompt = SYSTEM_PROMPT.format(                                  │
│      directory=config.workspace_root,                                   │
│      context=context                                                     │
│  )                                                                       │
├──────────────────────────────────────────────────────────────────────────┤
│  context 包含:                                                           │
│  ├── "✅ 简历已加载" 或 "⚠️ 简历未加载"                                   │
│  └── "📄 当前简历文件: /path/to/resume.md" (如果已加载)                   │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  next_step_prompt = _generate_next_step_prompt(intent)                  │
├──────────────────────────────────────────────────────────────────────────┤
│  ├── GREETING/UNKNOWN → "" (空字符串，让 LLM 自然回答)                   │
│  ├── 有分析工具结果 → 返回结果展示模板                                   │
│  └── 其他 → NEXT_STEP_PROMPT (默认)                                     │
└──────────────────────────────────────────────────────────────────────────┘
                                ↓
┌──────────────────────────────────────────────────────────────────────────┐
│  返回: (system_prompt, next_step_prompt)                                │
└──────────────────────────────────────────────────────────────────────────┘
```

### 代码实现

**文件**: [app/agent/manus.py:199-298](app/agent/manus.py#L199-L298)

```python
async def _generate_dynamic_prompts(self, user_input: str, intent: "Intent" = None) -> tuple:
    """
    根据用户输入和对话状态动态生成提示词

    返回: (system_prompt, next_step_prompt)
    """
    # 1. 生成上下文描述
    context_parts = []
    if self._conversation_state.context.resume_loaded:
        context_parts.append("✅ 简历已加载")
    else:
        context_parts.append("⚠️ 简历未加载，建议先加载简历")

    if self._current_resume_path:
        context_parts.append(f"📄 当前简历文件: {self._current_resume_path}")

    context = "\n".join(context_parts) if context_parts else "初始状态"

    # 2. 生成系统提示词（注入上下文）
    system_prompt = SYSTEM_PROMPT.format(
        directory=config.workspace_root,
        context=context
    )

    # 3. 生成下一步提示词
    next_step = await self._generate_next_step_prompt(intent)

    return system_prompt, next_step


async def _generate_next_step_prompt(self, intent: "Intent" = None) -> str:
    """生成下一步提示词"""
    # 🔑 对话类意图：返回空字符串，避免重复消息
    if intent in [Intent.GREETING, Intent.UNKNOWN]:
        return ""

    # 检查是否有分析工具刚执行完
    for msg in reversed(self.memory.messages[-3:]):
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            for tc in msg.tool_calls:
                if tc.function.name in ['education_analyzer', 'cv_analyzer_agent']:
                    # 获取分析结果
                    for result_msg in reversed(self.memory.messages[-10:]):
                        if result_msg.role == "tool" and result_msg.name in ['education_analyzer', 'cv_analyzer_agent']:
                            analysis_content = result_msg.content[:5000]
                            tool_display_name = "教育经历" if result_msg.name == "education_analyzer" else "简历"
                            return f"""## 分析完成，请展示结果

分析工具 ({result_msg.name}) 已返回结果，请向用户展示：

{analysis_content[:2000]}

请用中文向用户展示分析结果摘要和优化建议，然后询问是否要应用优化。"""

    return NEXT_STEP_PROMPT
```

### SYSTEM_PROMPT 模板

**文件**: [app/prompt/manus.py:7-37](app/prompt/manus.py#L7-L37)

```python
SYSTEM_PROMPT = """You are OpenManus, an AI assistant for resume optimization.

## Core Principles

1. **Resume-related tasks** → Use appropriate tools
2. **General questions** → Answer directly using your knowledge, NO tools
3. **Understand context** → Consider conversation history and resume state

## Available Tools

| Tool | When to Use |
|------|-------------|
| cv_reader_agent | Load resume from file path |
| cv_analyzer_agent | Analyze resume quality and content |
| education_analyzer | Analyze education background specifically |
| cv_editor_agent | Edit resume content |
| terminate | Complete the task |

## Guidelines

- **DO** use tools for resume operations (loading, analyzing, editing)
- **DO NOT** use browser/search tools for general knowledge questions
- **DO** answer common questions directly using your own knowledge
- **DO** call terminate when the task is complete
- Working language: Chinese

Current directory: {directory}
Current state: {context}
"""
```

### 动态 Prompt 的决策树

```
用户输入
    ↓
意图识别 (LLM classify_intent_with_llm)
    ↓
┌─────────────────────────────────────────────────────────────────┐
│ Intent.GREETING                                                 │
│ → system_prompt: 默认模板                                       │
│ → next_step_prompt: "" (空，让 LLM 自然问候)                   │
└─────────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────────┐
│ Intent.LOAD_RESUME                                              │
│ → system_prompt: 默认模板 + "简历未加载"                         │
│ → next_step_prompt: NEXT_STEP_PROMPT                            │
│ → 直接调用工具，跳过 LLM 决策                                    │
└─────────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────────┐
│ Intent.UNKNOWN                                                  │
│ → system_prompt: 根据当前状态动态生成                            │
│   - 简历已加载: "✅ 简历已加载"                                  │
│   - 简历未加载: "⚠️ 简历未加载"                                 │
│ → next_step_prompt: "" (空，让 LLM 自由判断)                    │
└─────────────────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────────────────┐
│ 分析工具刚执行完                                                 │
│ → system_prompt: 默认模板                                       │
│ → next_step_prompt: 动态生成结果展示模板                        │
│   "分析工具已返回结果，请向用户展示：\n{analysis_content}"      │
└─────────────────────────────────────────────────────────────────┘
```

---

## 未来动态 Prompt 设计

### 当前问题分析

| 问题 | 当前表现 | 影响 |
|------|----------|------|
| **上下文信息稀疏** | 只传递"简历已加载/未加载" | LLM 不知道简历具体内容 |
| **无引用机制** | LLM 需要重新加载简历才能回答 | 浪费 token |
| **无摘要传递** | 长对话后早期上下文丢失 | 滑动窗口裁剪关键信息 |
| **无进度状态** | LLM 不知道当前优化到哪一步 | 可能重复操作 |

### 未来设计方向

#### 1. 结构化上下文注入

```python
@dataclass
class ResumeContext:
    """简历上下文"""
    is_loaded: bool
    file_path: Optional[str]
    basic_info: Optional[Dict]  # 姓名、学校、专业
    sections: List[str]         # 已加载的章节
    last_analysis: Optional[str]  # 最近分析结果摘要
    optimization_history: List[str]  # 优化历史


async def _generate_dynamic_prompts_v2(self, user_input: str, intent: Intent) -> tuple:
    """V2: 结构化上下文注入"""
    # 构建结构化上下文
    resume_context = ResumeContext(
        is_loaded=self._conversation_state.context.resume_loaded,
        file_path=self._current_resume_path,
        basic_info=self._get_resume_basic_info(),  # 从 memory 或缓存提取
        sections=self._get_loaded_sections(),
        last_analysis=self._get_last_analysis_summary(),
        optimization_history=self._conversation_state.context.optimization_history
    )

    # 生成上下文提示词
    context_prompt = self._format_context_prompt(resume_context)

    system_prompt = SYSTEM_PROMPT.format(
        directory=config.workspace_root,
        context=context_prompt
    )

    return system_prompt, ""
```

**上下文提示词格式**：

```markdown
## 当前状态

### 简历状态
✅ 简历已加载: /path/to/resume.md

### 基本信息
- 姓名: 张三
- 学校: 中山大学
- 专业: 计算机科学与技术
- 年级: 2024届本科

### 已加载章节
- 教育经历 ✅
- 工作经验 ✅
- 项目经验 ⚠️ (未加载)

### 最近分析
- 教育经历分析: 综合评分 85/100
- 主要建议: 增加 GPA 描述，补充相关课程

### 优化历史
1. 2026-01-06: 教育经历 - 增加了 GPA 描述
2. 2026-01-05: 个人简介 - 简化了语言表达
```

#### 2. 引用机制 (Reference Mechanism)

```python
def _generate_context_with_references(self, max_tokens: int = 2000) -> str:
    """生成带引用的上下文

    类似 RAG 的引用机制，LLM 可以直接引用简历内容，
    而不需要重新加载整个简历。
    """
    references = []

    # 1. 基本信息 (始终包含)
    if self._resume_basic_info:
        references.append(f"""
[基本信息]
{json.dumps(self._resume_basic_info, ensure_ascii=False)}
""")

    # 2. 根据意图选择相关章节
    intent = self._last_intent
    if intent == Intent.EDUCATION_ANALYSIS:
        section = self._get_resume_section("education")
        references.append(f"""
[教育经历]
{section}
""")
    elif intent == Intent.WORK_EXPERIENCE:
        section = self._get_resume_section("work")
        references.append(f"""
[工作经验]
{section}
""")

    # 3. 限制 token 数量
    context = "\n".join(references)
    if self.llm.count_tokens(context) > max_tokens:
        context = self._truncate_context(context, max_tokens)

    return context
```

#### 3. 摘要传递机制 (Summary Propagation)

```python
class ConversationSummary:
    """对话摘要"""

    def __init__(self):
        self.turn_count = 0
        self.key_points: List[str] = []
        self.user_profile: Dict[str, Any] = {}
        self.current_task: Optional[str] = None
        self.pending_items: List[str] = []

    def add_turn(self, user_input: str, ai_response: str, tool_results: List[ToolResult]):
        """添加一轮对话，更新摘要"""
        self.turn_count += 1

        # 提取关键点
        if "简历" in user_input and "加载" in user_input:
            self.key_points.append(f"第{self.turn_count}轮: 用户加载了简历")

        # 更新用户画像
        self._update_user_profile(user_input, tool_results)

        # 更新当前任务
        if "优化" in user_input:
            self.current_task = self._extract_task(user_input)

    def to_context_prompt(self) -> str:
        """转换为上下文提示词"""
        parts = []
        if self.key_points:
            parts.append("## 对话关键点\n" + "\n".join(self.key_points[-5:]))
        if self.current_task:
            parts.append(f"## 当前任务\n{self.current_task}")
        if self.pending_items:
            parts.append("## 待处理\n" + "\n".join(self.pending_items))
        return "\n\n".join(parts)
```

#### 4. 进度状态追踪

```python
@dataclass
class OptimizationProgress:
    """优化进度"""
    current_section: str = ""
    completed_sections: List[str] = field(default_factory=list)
    current_step: int = 0
    total_steps: int = 0
    pending_questions: List[Dict] = field(default_factory=list)
    applied_suggestions: List[str] = field(default_factory=list)

    def to_progress_prompt(self) -> str:
        """生成进度提示词"""
        if self.total_steps == 0:
            return ""

        progress_bar = "█" * self.current_step + "░" * (self.total_steps - self.current_step)
        return f"""
## 当前进度
{progress_bar} ({self.current_step}/{self.total_steps})

当前优化: {self.current_section}
已完成: {", ".join(self.completed_sections) or "无"}
"""
```

### 未来 Prompt 架构

```
┌──────────────────────────────────────────────────────────────────────────┐
│  System Prompt (V2)                                                      │
├──────────────────────────────────────────────────────────────────────────┤
│  [固定部分]                                                              │
│  ├── 角色定义: "你是 OpenManus..."                                       │
│  ├── 工具列表: cv_reader_agent, cv_analyzer_agent, ...                   │
│  └── 核心原则: 简历相关用工具，常识问题直接回答                           │
│                                                                          │
│  [动态部分]                                                              │
│  ├── 结构化上下文: ResumeContext                                         │
│  │   ├── 基本信息: 姓名、学校、专业                                      │
│  │   ├── 已加载章节: 教育、工作、项目                                    │
│  │   ├── 最近分析: 综合评分、主要建议                                    │
│  │   └── 优化历史: 已应用的优化                                          │
│  ├── 引用内容: 根据意图选择相关章节                                      │
│  ├── 对话摘要: 关键点、用户画像、当前任务                                │
│  └── 进度状态: 当前优化到哪一步                                          │
└──────────────────────────────────────────────────────────────────────────┘
```

### 实现优先级

| 优先级 | 功能 | 预期收益 | 实现难度 |
|--------|------|----------|----------|
| P0 | 结构化上下文注入 | LLM 更清楚当前状态 | 中 |
| P1 | 引用机制 | 减少 token 消耗 | 高 |
| P1 | 对话摘要 | 长对话保持上下文 | 中 |
| P2 | 进度状态追踪 | 避免重复操作 | 低 |
| P3 | 智能上下文压缩 | 支持更长对话 | 高 |

---

## 总结

### 当前上下文传递机制的特点

1. **双层记忆系统**
   - `Memory`: 运行时，50 条消息
   - `ChatHistoryManager`: 持久化，30 条消息

2. **完整性保证**
   - tool 消息通过 `tool_call_id` 与 tool_calls 关联
   - `cleanup_incomplete_sequences()` 清理不完整序列

3. **动态 Prompt**
   - System Prompt 包含当前状态
   - next_step_prompt 根据意图和最近工具结果生成

4. **去重机制**
   - `_should_add_next_step_prompt()` 避免重复添加

### 未来优化方向

1. **结构化上下文**: 从简单状态描述到完整的 ResumeContext
2. **引用机制**: 类似 RAG，按需加载简历章节
3. **摘要传递**: 长对话时传递摘要而非完整历史
4. **进度追踪**: 让 LLM 知道当前优化进度
