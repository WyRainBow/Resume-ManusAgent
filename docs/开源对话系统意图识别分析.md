# 开源对话系统意图识别分析

## 一、主流开源项目的做法

### 1. **Rasa（NLU + 对话管理）**
- **NLU模块**：训练专门的意图分类模型（BERT-based）
- **对话管理**：使用策略学习（Policy Learning）管理对话流程
- **优点**：可训练、可定制、准确率高
- **缺点**：需要大量标注数据，训练成本高

### 2. **ChatGPT/Claude 等 LLM 的做法**
- **利用预训练能力**：模型已经理解语言模式
- **Few-shot Prompting**：通过示例让模型理解意图
- **上下文理解**：利用对话历史理解当前意图
- **优点**：无需训练，灵活，理解能力强
- **缺点**：需要好的提示词设计

### 3. **LangChain + LLM 的做法**
- **Chain of Thought**：让模型逐步推理
- **Tool Calling**：让模型自己决定调用哪个工具
- **Memory Management**：维护对话上下文

## 二、我们当前实现的问题

### 当前方法：基于关键词的模式匹配
```python
# 问题1：职责相关
duty_keywords = ["负责", "主要负责", "职责", ...]
if any(kw in input_text for kw in duty_keywords):
    return {"question": "问题1", ...}
```

**局限性**：
1. ❌ 不够灵活：用户表达方式多样，关键词覆盖不全
2. ❌ 容易误判：关键词可能出现在不同上下文中
3. ❌ 无法理解语义：不知道"我负责开发"和"他负责开发"的区别
4. ❌ 维护成本高：需要不断添加关键词

## 三、改进方案：利用 LLM 做意图识别

### 方案1：使用 LLM 进行意图分类（推荐）

```python
async def classify_intent_with_llm(
    user_input: str,
    conversation_history: List[Message],
    last_ai_message: Optional[str] = None
) -> Dict[str, Any]:
    """
    使用 LLM 进行意图分类

    优势：
    1. 理解语义，不依赖关键词
    2. 考虑上下文，更准确
    3. 灵活，能处理各种表达方式
    """

    prompt = f"""
你是一个专业的意图识别助手。根据用户输入和对话历史，识别用户的真实意图。

## 对话历史
{format_history(conversation_history[-5:])}

## 最后一条AI消息
{last_ai_message or "无"}

## 用户当前输入
{user_input}

## 可选的意图类型
1. greeting - 问候（你好、hi等）
2. load_resume - 加载简历
3. view_resume - 查看/介绍简历
4. analyze - 分析简历
5. optimize_section - 优化特定模块（如"优化工作经历"）
6. answer_question - 回答问题（当AI问了问题后，用户的回答）
7. confirm - 确认（可以、好的、确认）
8. unknown - 其他

## 特殊规则
- 如果最后一条AI消息包含"问题1"、"问题2"、"问题3"，且用户输入是回答，则识别为 answer_question
- 如果用户输入包含"优化"+"具体模块名"（如工作经历、个人总结），则识别为 optimize_section
- 如果用户输入是简短确认词，则识别为 confirm

请以JSON格式返回：
{{
    "intent": "意图类型",
    "confidence": 0.95,
    "extracted_info": {{
        "section": "工作经历",  // 如果是优化模块
        "question": "问题1",     // 如果是回答问题
        "answer_type": "duties" // duties/results/technologies
    }},
    "reasoning": "识别理由"
}}
"""

    # 调用 LLM
    response = await llm_client.chat_completion(
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.content)
```

### 方案2：Few-shot Prompting（更简单）

```python
INTENT_CLASSIFICATION_EXAMPLES = """
示例1:
用户: "帮我优化工作经历"
意图: optimize_section
模块: 工作经历

示例2:
用户: "我主要负责前端开发，使用React和TypeScript"
上下文: AI刚才问了"问题1: 您主要负责哪些工作？"
意图: answer_question
问题: 问题1
类型: duties

示例3:
用户: "性能提升了30%，用户增长了50%"
上下文: AI刚才问了"问题2: 您取得了哪些成果？"
意图: answer_question
问题: 问题2
类型: results
"""

async def classify_intent_few_shot(user_input: str, context: str) -> str:
    prompt = f"""
{INTENT_CLASSIFICATION_EXAMPLES}

现在请识别：
用户输入: {user_input}
上下文: {context}

只返回意图类型（如：optimize_section, answer_question等）
"""
    return await llm_client.complete(prompt)
```

### 方案3：混合方案（最佳实践）

```python
class LLMIntentClassifier:
    """使用 LLM 进行意图识别"""

    async def classify(
        self,
        user_input: str,
        conversation_history: List[Message],
        last_ai_message: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        混合方案：
        1. 先用简单规则过滤明显的情况（如问候）
        2. 复杂情况用 LLM 判断
        3. 缓存常见意图，减少 LLM 调用
        """

        # 快速路径：明显的情况
        if self._is_obvious_greeting(user_input):
            return {"intent": "greeting", "confidence": 1.0}

        # LLM 路径：复杂情况
        return await self._llm_classify(user_input, conversation_history, last_ai_message)
```

## 四、为什么 ChatGPT 能精确理解意图？

### 1. **大规模预训练**
- 学习了海量文本中的语言模式
- 理解各种表达方式的语义

### 2. **上下文理解能力**
- Transformer 的自注意力机制
- 能理解长距离依赖关系

### 3. **Few-shot Learning**
- 通过示例快速学习新任务
- 不需要重新训练模型

### 4. **Chain of Thought**
- 逐步推理，而不是直接输出
- 能处理复杂逻辑

## 五、实施建议

### 短期改进（立即可做）
1. **使用 LLM 做意图识别**：替换关键词匹配
2. **添加 Few-shot Examples**：提高准确性
3. **利用对话历史**：让模型理解上下文

### 中期改进
1. **意图分类缓存**：常见意图直接返回，减少 LLM 调用
2. **置信度阈值**：低置信度时回退到规则匹配
3. **错误反馈机制**：收集误判案例，优化提示词

### 长期改进
1. **Fine-tuning**：在简历优化领域微调模型
2. **多模型融合**：规则 + LLM + 传统ML模型
3. **持续学习**：从用户反馈中学习

## 六、代码示例：改进后的意图识别

```python
class ImprovedConversationManager:
    """改进的对话管理器 - 使用 LLM 进行意图识别"""

    def __init__(self, llm_client):
        self.llm = llm_client
        self.cache = {}  # 意图缓存

    async def classify_intent(
        self,
        user_input: str,
        history: List[Message],
        last_ai_msg: Optional[str] = None
    ) -> Dict[str, Any]:
        """使用 LLM 分类意图"""

        # 检查缓存
        cache_key = self._get_cache_key(user_input, last_ai_msg)
        if cache_key in self.cache:
            return self.cache[cache_key]

        # 构建提示词
        prompt = self._build_intent_prompt(user_input, history, last_ai_msg)

        # 调用 LLM
        response = await self.llm.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.1  # 低温度，更确定
        )

        result = json.loads(response.content)

        # 缓存结果
        if result.get("confidence", 0) > 0.9:
            self.cache[cache_key] = result

        return result

    def _build_intent_prompt(
        self,
        user_input: str,
        history: List[Message],
        last_ai_msg: Optional[str] = None
    ) -> str:
        """构建意图识别提示词"""

        # 提取最近3轮对话
        recent_history = self._format_history(history[-6:])

        return f"""
你是一个专业的意图识别助手。根据用户输入和对话上下文，准确识别用户意图。

## 对话历史
{recent_history}

## 最后一条AI消息
{last_ai_msg or "无"}

## 用户当前输入
"{user_input}"

## 意图类型说明
- greeting: 问候（你好、hi等）
- load_resume: 加载简历
- view_resume: 查看/介绍简历
- analyze: 分析简历
- optimize_section: 优化特定模块（如"优化工作经历"、"优化个人总结"）
- answer_question: 回答AI的问题（当AI问了问题后，用户的回答）
- confirm: 确认（可以、好的、确认、开始）
- unknown: 其他

## 识别规则
1. 如果AI刚问了"问题1/2/3"，用户输入是回答，则识别为 answer_question
2. 如果用户说"优化XX"（XX是具体模块），则识别为 optimize_section
3. 如果用户说简短确认词，则识别为 confirm
4. 考虑对话上下文，不要只看当前输入

## 输出格式（JSON）
{{
    "intent": "意图类型",
    "confidence": 0.0-1.0,
    "extracted_info": {{
        "section": "模块名（如果有）",
        "question": "问题编号（如果是回答）",
        "answer_type": "duties/results/technologies"
    }},
    "reasoning": "识别理由（简短）"
}}
"""
```

## 七、总结

### 关键点
1. **不要依赖关键词匹配**：不够灵活，容易误判
2. **利用 LLM 的预训练能力**：它已经理解语言
3. **提供上下文**：让模型理解对话历史
4. **Few-shot Learning**：通过示例引导模型
5. **混合方案**：简单情况用规则，复杂情况用 LLM

### 为什么 ChatGPT 能精确理解？
- ✅ 大规模预训练：理解语言模式
- ✅ 上下文理解：利用对话历史
- ✅ Few-shot 能力：通过示例学习
- ✅ 推理能力：能理解复杂逻辑

### 我们的改进方向
1. 用 LLM 替换关键词匹配
2. 提供更好的上下文和示例
3. 利用对话历史理解意图
4. 持续优化提示词


